{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3228fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.dataset_utils import *\n",
    "from collections import defaultdict\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from marl_aquarium.env.utils import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "825908b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data):\n",
    "    prey_pts = []\n",
    "    pred_pts = None\n",
    "    result = data[\"annotations\"][0][\"result\"]\n",
    "    for r in result:\n",
    "        width, height = r[\"original_width\"], r[\"original_height\"]\n",
    "        value = r[\"value\"]\n",
    "        x = (value[\"x\"] / 100.0) * width\n",
    "        y = (value[\"y\"] / 100.0) * height\n",
    "        labels = value.get(\"keypointlabels\", [])\n",
    "        label = labels[0] if labels else \"Prey\"\n",
    "        if label == \"Predator\":\n",
    "            pred_pts = (x, y)\n",
    "        else:\n",
    "            prey_pts.append((x, y))\n",
    "\n",
    "    pred_arr = np.array([pred_pts])\n",
    "    prey_arr = np.array(prey_pts)\n",
    "    return pred_arr, prey_arr\n",
    "\n",
    "def hungarian_assign(point_seq):\n",
    "    ordered = [point_seq[0]]\n",
    "    prev = point_seq[0]\n",
    "\n",
    "    for t in range(1, len(point_seq)):\n",
    "        current_point = point_seq[t]\n",
    "        distance = np.linalg.norm(prev[:, None, :] - current_point[None, :, :], axis=2)\n",
    "        _, col_ind = linear_sum_assignment(distance)\n",
    "        curr_ord = current_point[col_ind]\n",
    "        ordered.append(curr_ord)\n",
    "        prev = curr_ord\n",
    "\n",
    "    ordered = np.stack(ordered, axis=0)  # (T, N, 2)\n",
    "    return ordered\n",
    "\n",
    "def get_velocity(positions):\n",
    "    velocities = []\n",
    "    for i in range(1, len(positions)):\n",
    "        velo = positions[i] - positions[i - 1]\n",
    "        velocity = velo / 2 #every second frame got labeled\n",
    "        velocities.append(velocity)\n",
    "    return np.array(velocities)\n",
    "\n",
    "\n",
    "def get_records(pred_ordered, prey_ordered, pred_velocities, prey_velocities):\n",
    "    records = []\n",
    "    T = pred_velocities.shape[0]\n",
    "    M = prey_ordered.shape[1]\n",
    "\n",
    "    for step in range(T):\n",
    "        # Predator (immer Index 0)\n",
    "        x  = float(pred_ordered[step, 0, 0])\n",
    "        y  = float(pred_ordered[step, 0, 1])\n",
    "        vx = float(pred_velocities[step, 0, 0])\n",
    "        vy = float(pred_velocities[step, 0, 1])\n",
    "\n",
    "        records.append({\n",
    "            \"frame\": step,\n",
    "            \"label\": \"Predator\",\n",
    "            \"conf\": 1.0,\n",
    "            \"x\": x, \"y\": y,\n",
    "            \"vx\": vx, \"vy\": vy,\n",
    "            \"speed\": float(math.hypot(vx, vy)),\n",
    "            \"angle\": float(math.atan2(vy, vx)),\n",
    "        })\n",
    "\n",
    "        # Preys (Index 0..M-1)\n",
    "        for i in range(M):\n",
    "            x  = float(prey_ordered[step, i, 0])   # <-- step, i, ...\n",
    "            y  = float(prey_ordered[step, i, 1])\n",
    "            vx = float(prey_velocities[step, i, 0])\n",
    "            vy = float(prey_velocities[step, i, 1])\n",
    "\n",
    "            records.append({\n",
    "                \"frame\": step,\n",
    "                \"label\": \"Prey\",\n",
    "                \"conf\": 1.0,\n",
    "                \"x\": x, \"y\": y,\n",
    "                \"vx\": vx, \"vy\": vy,\n",
    "                \"speed\": float(math.hypot(vx, vy)),\n",
    "                \"angle\": float(math.atan2(vy, vx)),\n",
    "            })\n",
    "\n",
    "    return records\n",
    "\n",
    "\n",
    "\n",
    "def get_expert_features(frame, width, height, max_speed):    \n",
    "    vscale = np.vectorize(scale)\n",
    "\n",
    "    xs = np.array([float(np.asarray(det['x']).reshape(-1)[0]) for det in frame])\n",
    "    ys = np.array([float(np.asarray(det['y']).reshape(-1)[0]) for det in frame])\n",
    "    scaled_xs = vscale(xs, 0, width, 0, 1)\n",
    "    scaled_ys = vscale(ys, 0, height, 0, 1)\n",
    "\n",
    "    vxs = np.array([float(np.asarray(det['vx']).reshape(-1)[0]) for det in frame])\n",
    "    vys = np.array([float(np.asarray(det['vy']).reshape(-1)[0]) for det in frame])\n",
    "\n",
    "    thetas = np.array([det['angle'] for det in frame])\n",
    "    scaled_thetas = vscale(thetas, -np.pi, np.pi, 0, 1)\n",
    "\n",
    "    cos_t = np.cos(thetas)                        \n",
    "    sin_t = np.sin(thetas)\n",
    "\n",
    "    # pairwise distances\n",
    "    dx = scaled_xs[None, :] - scaled_xs[:, None]\n",
    "    dy = scaled_ys[None, :] - scaled_ys[:, None]\n",
    "\n",
    "    # relative velocities\n",
    "    rel_vx = cos_t[:, None] * vxs[None, :] + sin_t[:, None] * vys[None, :]\n",
    "    rel_vy = -sin_t[:, None] * vxs[None, :] + cos_t[:, None] * vys[None, :]\n",
    "\n",
    "    rel_vx = np.clip(rel_vx, -max_speed, max_speed)\n",
    "    rel_vy = np.clip(rel_vy, -max_speed, max_speed)\n",
    "    \n",
    "    scaled_rel_vx = vscale(rel_vx, -max_speed, max_speed, -1, 1)\n",
    "    scaled_rel_vy = vscale(rel_vy, -max_speed, max_speed, -1, 1)\n",
    "\n",
    "    n = scaled_xs.shape[0]\n",
    "    thetas_mat = np.tile(scaled_thetas[:, None], (1, n))\n",
    "    features = np.stack([dx, dy, scaled_rel_vx, scaled_rel_vy, thetas_mat], axis=-1)\n",
    "\n",
    "    mask = ~np.eye(n, dtype=bool) # shape (N, N)\n",
    "    neigh = features[mask].reshape(n, n-1, 5)\n",
    "\n",
    "    pred_tensor = torch.from_numpy(neigh[0]).unsqueeze(0)\n",
    "    prey_tensor = torch.from_numpy(neigh[1:]) # shape (N-1, N-1, 5)\n",
    "\n",
    "    return pred_tensor, prey_tensor\n",
    "\n",
    "\n",
    "def get_expert_tensors(records, max_speed):\n",
    "    preds = []\n",
    "    preys = []\n",
    "\n",
    "    frame_ids = sorted({rec[\"frame\"] for rec in records})\n",
    "    for frame_idx in frame_ids:\n",
    "        frame = [rec for rec in records if rec[\"frame\"] == frame_idx]\n",
    "        if not frame:\n",
    "            continue\n",
    "        pred_tensor, prey_tensor = get_expert_features(frame, width=2160, height=2160, max_speed=max_speed)\n",
    "        preds.append(pred_tensor)\n",
    "        preys.append(prey_tensor)\n",
    "\n",
    "    pred_tensor = torch.stack(preds, dim=0)\n",
    "    prey_tensor = torch.stack(preys, dim=0)\n",
    "\n",
    "    return pred_tensor, prey_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9d2365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_windows(tensor, window_len):\n",
    "    n_frames = tensor.shape[0]\n",
    "    windows = []\n",
    "\n",
    "    for start in range(0, n_frames - window_len + 1):\n",
    "        windows.append(tensor[start:start + window_len])\n",
    "\n",
    "    return torch.stack(windows, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc03fd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred Tensors Shape: (769, 10, 1, 32, 5)\n",
      "Prey Tensors Shape: (769, 10, 32, 32, 6)\n"
     ]
    }
   ],
   "source": [
    "data_folder = rf'..\\data\\1. Data Processing\\raw\\pred_attack'\n",
    "tensor_folder = rf'..\\data\\1. Data Processing\\processed\\video\\expert_tensors\\windows'\n",
    "window_len = 10\n",
    "\n",
    "pred_tensors_list = []\n",
    "prey_tensors_list = []\n",
    "\n",
    "for file in os.listdir(data_folder):\n",
    "    if file.endswith(\".json\"):\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        pairs = [scale_data(pts) for pts in data]\n",
    "        pred_pts = [p for p, _ in pairs] \n",
    "        prey_pts = [q for _, q in pairs]\n",
    "\n",
    "        pred_ordered = hungarian_assign(pred_pts)\n",
    "        prey_ordered = hungarian_assign(prey_pts)\n",
    "\n",
    "        pred_velocities = get_velocity(pred_ordered) #vx, vy\n",
    "        prey_velocities = get_velocity(prey_ordered)\n",
    "\n",
    "        records = get_records(pred_ordered, prey_ordered, pred_velocities, prey_velocities)\n",
    "\n",
    "        pred_tensor, prey_tensor = get_expert_tensors(records, max_speed=10)\n",
    "\n",
    "        pred_windows = extract_windows(pred_tensor, window_len=window_len)\n",
    "        prey_windows = extract_windows(prey_tensor, window_len=window_len)\n",
    "\n",
    "        pred_tensors_list.append(pred_windows)\n",
    "        prey_tensors_list.append(prey_windows)\n",
    "\n",
    "pred_tensors = torch.cat(pred_tensors_list, dim=0)\n",
    "prey_tensors = torch.cat(prey_tensors_list, dim=0)\n",
    "\n",
    "n, window, agents, neighs, feature = prey_tensors.shape\n",
    "flag = torch.zeros((n, window, agents, neighs, 1), dtype=prey_tensors.dtype, device=prey_tensors.device)\n",
    "flag[:, :1, 0] = 1\n",
    "prey_tensors = torch.cat([flag, prey_tensors], dim=-1)\n",
    "\n",
    "pred_path = os.path.join(tensor_folder, f\"{window_len} windows\" , f\"pred_tensors_hl_w{window_len}_n{len(pred_tensors)}.pkl\")\n",
    "prey_path = os.path.join(tensor_folder, f\"{window_len} windows\" , f\"prey_tensors_hl_w{window_len}_n{len(prey_tensors)}.pkl\")\n",
    "\n",
    "torch.save(pred_tensors, pred_path)\n",
    "torch.save(prey_tensors, prey_path)\n",
    "\n",
    "print(\"Pred Tensors Shape:\", tuple(pred_tensors.shape))\n",
    "print(\"Prey Tensors Shape:\", tuple(prey_tensors.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAIL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
