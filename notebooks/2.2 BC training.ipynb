{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3228fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import pickle\n",
    "import datetime\n",
    "from utils.es_utils import *\n",
    "from utils.env_utils import *\n",
    "from utils.train_utils import *\n",
    "from models.Buffer import Buffer\n",
    "from models.PredatorPolicy import PredatorPolicy\n",
    "from models.PreyPolicy import PreyPolicy\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from models.Buffer import Pool\n",
    "from utils.env_utils import *\n",
    "from utils.eval_utils import *\n",
    "from utils.train_utils import pretrain_policy_with_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ef35ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training folder\n",
    "path = rf\"..\\data\\2. Training\\training\\BC\"\n",
    "timestamp = datetime.datetime.now().strftime(\"%d.%m.%Y_%H.%M\")\n",
    "folder_name = f\"BC Training - {timestamp} - Video Data\"\n",
    "save_dir = os.path.join(path, folder_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Expert Data\n",
    "traj_path = rf'..\\data\\1. Data Processing\\processed\\video\\expert_tensors\\yolo_detected'\n",
    "couzin_path = rf'..\\data\\1. Data Processing\\processed\\couzin'\n",
    "hl_path = rf'..\\data\\1. Data Processing\\processed\\video\\expert_tensors\\hand_labeled'\n",
    "ftw_path = rf'..\\data\\1. Data Processing\\processed\\video\\3. full_track_windows'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7593b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start frames in pool: 11978\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pred_policy = PredatorPolicy().to(device)\n",
    "pred_policy.set_parameters(init=True)\n",
    "\n",
    "prey_policy = PreyPolicy(gain=0.0).to(device)\n",
    "prey_policy.set_parameters(init=True)\n",
    "\n",
    "expert_buffer = Buffer(pred_max_length=23000, prey_max_length=200000, device=device)\n",
    "\n",
    "ftw_path = rf'..\\data\\1. Data Processing\\processed\\video\\3. full_track_windows'\n",
    "start_frame_pool = Pool(max_length=12100, device=device)\n",
    "start_frame_pool.generate_startframes(ftw_path)\n",
    "print(f\"Start frames in pool: {len(start_frame_pool)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f23d55eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert Buffer is empty, load data...\n",
      "Storage of Predator Expert Buffer:  1000\n",
      "Storage of Prey Expert Buffer:  32000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Expert Data from local storage\n",
    "print(\"Expert Buffer is empty, load data...\")\n",
    "expert_buffer.add_expert(couzin_path)\n",
    "#expert_buffer.clear(p=80)               # Reduce ratio of non-attack data by 90%. now ~equal\n",
    "#expert_buffer.add_expert(hl_path)       # hand-labeled data | Pred: 1057 | Prey: 33824\n",
    "\n",
    "len_exp_pred, len_exp_prey = expert_buffer.lengths()\n",
    "print(\"Storage of Predator Expert Buffer: \", len_exp_pred)\n",
    "print(\"Storage of Prey Expert Buffer: \", len_exp_prey, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a956b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PREDATOR] Epoch 01 | Train Loss: 0.302294 | Val Loss: 0.543975\n",
      "[PREDATOR] Epoch 02 | Train Loss: 0.305558 | Val Loss: 0.826540\n",
      "[PREDATOR] Epoch 03 | Train Loss: 0.340208 | Val Loss: 0.558134\n",
      "[PREDATOR] Epoch 04 | Train Loss: 0.376557 | Val Loss: 0.737611\n",
      "[PREDATOR] Epoch 05 | Train Loss: 0.356201 | Val Loss: 0.549937\n",
      "[PREDATOR] Epoch 06 | Train Loss: 0.264818 | Val Loss: 0.588976\n",
      "[PREDATOR] Epoch 07 | Train Loss: 0.329097 | Val Loss: 0.637491\n",
      "[PREDATOR] Epoch 08 | Train Loss: 0.261394 | Val Loss: 0.521032\n",
      "[PREDATOR] Epoch 09 | Train Loss: 0.319150 | Val Loss: 0.393460\n",
      "[PREDATOR] Epoch 10 | Train Loss: 0.411461 | Val Loss: 0.421946\n",
      "[PREDATOR] Epoch 11 | Train Loss: 0.332232 | Val Loss: 0.491938\n",
      "[PREDATOR] Epoch 12 | Train Loss: 0.405246 | Val Loss: 0.586267\n",
      "[PREDATOR] Epoch 13 | Train Loss: 0.213983 | Val Loss: 0.646619\n",
      "[PREDATOR] Epoch 14 | Train Loss: 0.238107 | Val Loss: 0.545211\n",
      "[PREDATOR] Epoch 15 | Train Loss: 0.260720 | Val Loss: 0.257376\n",
      "[PREDATOR] Epoch 16 | Train Loss: 0.227228 | Val Loss: 0.448390\n",
      "[PREDATOR] Epoch 17 | Train Loss: 0.251076 | Val Loss: 0.182399\n",
      "[PREDATOR] Epoch 18 | Train Loss: 0.211546 | Val Loss: 0.607091\n",
      "[PREDATOR] Epoch 19 | Train Loss: 0.212483 | Val Loss: 0.253955\n",
      "[PREDATOR] Epoch 20 | Train Loss: 0.249177 | Val Loss: 0.134978\n",
      "[PREDATOR] Epoch 21 | Train Loss: 0.293896 | Val Loss: 0.306705\n",
      "[PREDATOR] Epoch 22 | Train Loss: 0.315370 | Val Loss: 0.297753\n",
      "[PREDATOR] Epoch 23 | Train Loss: 0.284447 | Val Loss: 0.639030\n",
      "[PREDATOR] Epoch 24 | Train Loss: 0.298935 | Val Loss: 0.406430\n",
      "[PREDATOR] Epoch 25 | Train Loss: 0.179507 | Val Loss: 0.324088\n",
      "[PREDATOR] Epoch 26 | Train Loss: 0.283015 | Val Loss: 0.269929\n",
      "[PREDATOR] Epoch 27 | Train Loss: 0.236742 | Val Loss: 0.545579\n",
      "[PREDATOR] Epoch 28 | Train Loss: 0.145472 | Val Loss: 0.482552\n",
      "[PREDATOR] Epoch 29 | Train Loss: 0.197431 | Val Loss: 0.443557\n",
      "[PREDATOR] Epoch 30 | Train Loss: 0.224662 | Val Loss: 0.273579\n",
      "[PREDATOR] Epoch 31 | Train Loss: 0.216338 | Val Loss: 0.530340\n",
      "[PREDATOR] Epoch 32 | Train Loss: 0.283908 | Val Loss: 0.336758\n",
      "[PREDATOR] Epoch 33 | Train Loss: 0.190847 | Val Loss: 0.469379\n",
      "[PREDATOR] Epoch 34 | Train Loss: 0.224122 | Val Loss: 0.405860\n",
      "[PREDATOR] Epoch 35 | Train Loss: 0.244277 | Val Loss: 0.347080\n",
      "[PREDATOR] Epoch 36 | Train Loss: 0.250994 | Val Loss: 0.218886\n",
      "[PREDATOR] Epoch 37 | Train Loss: 0.245466 | Val Loss: 0.438010\n",
      "[PREDATOR] Epoch 38 | Train Loss: 0.185679 | Val Loss: 0.234186\n",
      "[PREDATOR] Epoch 39 | Train Loss: 0.161903 | Val Loss: 0.282490\n",
      "[PREDATOR] Epoch 40 | Train Loss: 0.206405 | Val Loss: 0.363368\n",
      "[PREDATOR] Epoch 41 | Train Loss: 0.198433 | Val Loss: 0.228287\n",
      "[PREDATOR] Epoch 42 | Train Loss: 0.193166 | Val Loss: 0.277749\n",
      "[PREDATOR] Epoch 43 | Train Loss: 0.189966 | Val Loss: 0.198598\n",
      "[PREDATOR] Epoch 44 | Train Loss: 0.205118 | Val Loss: 0.225244\n",
      "[PREDATOR] Epoch 45 | Train Loss: 0.154872 | Val Loss: 0.173857\n",
      "[PREDATOR] Epoch 46 | Train Loss: 0.275650 | Val Loss: 0.276187\n",
      "[PREDATOR] Epoch 47 | Train Loss: 0.194586 | Val Loss: 0.252381\n",
      "[PREDATOR] Epoch 48 | Train Loss: 0.190545 | Val Loss: 0.358444\n",
      "[PREDATOR] Epoch 49 | Train Loss: 0.214760 | Val Loss: 0.249986\n",
      "[PREDATOR] Epoch 50 | Train Loss: 0.166986 | Val Loss: 0.148140\n",
      "[PREDATOR] Epoch 51 | Train Loss: 0.171227 | Val Loss: 0.211516\n",
      "[PREDATOR] Epoch 52 | Train Loss: 0.184376 | Val Loss: 0.320752\n",
      "[PREDATOR] Epoch 53 | Train Loss: 0.158724 | Val Loss: 0.309975\n",
      "[PREDATOR] Epoch 54 | Train Loss: 0.157096 | Val Loss: 0.129409\n",
      "[PREDATOR] Epoch 55 | Train Loss: 0.137900 | Val Loss: 0.151376\n",
      "[PREDATOR] Epoch 56 | Train Loss: 0.154976 | Val Loss: 0.245119\n",
      "[PREDATOR] Epoch 57 | Train Loss: 0.158360 | Val Loss: 0.174472\n",
      "[PREDATOR] Epoch 58 | Train Loss: 0.172294 | Val Loss: 0.192331\n",
      "[PREDATOR] Epoch 59 | Train Loss: 0.191635 | Val Loss: 0.204489\n",
      "[PREDATOR] Epoch 60 | Train Loss: 0.157742 | Val Loss: 0.303710\n",
      "[PREDATOR] Epoch 61 | Train Loss: 0.113194 | Val Loss: 0.303781\n",
      "[PREDATOR] Epoch 62 | Train Loss: 0.181542 | Val Loss: 0.134302\n",
      "[PREDATOR] Epoch 63 | Train Loss: 0.158149 | Val Loss: 0.248822\n",
      "[PREDATOR] Epoch 64 | Train Loss: 0.156455 | Val Loss: 0.217718\n",
      "[PREDATOR] Epoch 65 | Train Loss: 0.154508 | Val Loss: 0.264306\n",
      "[PREDATOR] Epoch 66 | Train Loss: 0.150302 | Val Loss: 0.368207\n",
      "[PREDATOR] Epoch 67 | Train Loss: 0.190440 | Val Loss: 0.359280\n",
      "[PREDATOR] Epoch 68 | Train Loss: 0.152425 | Val Loss: 0.112260\n",
      "[PREDATOR] Epoch 69 | Train Loss: 0.118414 | Val Loss: 0.147550\n",
      "[PREDATOR] Epoch 70 | Train Loss: 0.146823 | Val Loss: 0.220118\n",
      "[PREDATOR] Epoch 71 | Train Loss: 0.146832 | Val Loss: 0.325782\n",
      "[PREDATOR] Epoch 72 | Train Loss: 0.134605 | Val Loss: 0.220596\n",
      "[PREDATOR] Epoch 73 | Train Loss: 0.136816 | Val Loss: 0.103176\n",
      "[PREDATOR] Epoch 74 | Train Loss: 0.125694 | Val Loss: 0.095520\n",
      "[PREDATOR] Epoch 75 | Train Loss: 0.126912 | Val Loss: 0.122783\n",
      "[PREDATOR] Epoch 76 | Train Loss: 0.100112 | Val Loss: 0.284046\n",
      "[PREDATOR] Epoch 77 | Train Loss: 0.120991 | Val Loss: 0.210698\n",
      "[PREDATOR] Epoch 78 | Train Loss: 0.083446 | Val Loss: 0.186283\n",
      "[PREDATOR] Epoch 79 | Train Loss: 0.087957 | Val Loss: 0.161134\n",
      "[PREDATOR] Epoch 80 | Train Loss: 0.111561 | Val Loss: 0.242374\n",
      "[PREDATOR] Epoch 81 | Train Loss: 0.099114 | Val Loss: 0.261678\n",
      "[PREDATOR] Epoch 82 | Train Loss: 0.098507 | Val Loss: 0.166172\n",
      "[PREDATOR] Epoch 83 | Train Loss: 0.082072 | Val Loss: 0.147637\n",
      "[PREDATOR] Epoch 84 | Train Loss: 0.075063 | Val Loss: 0.110751\n",
      "[PREDATOR] Epoch 85 | Train Loss: 0.087034 | Val Loss: 0.114988\n",
      "[PREDATOR] Epoch 86 | Train Loss: 0.077972 | Val Loss: 0.135619\n",
      "[PREDATOR] Epoch 87 | Train Loss: 0.082061 | Val Loss: 0.116376\n",
      "[PREDATOR] Epoch 88 | Train Loss: 0.079336 | Val Loss: 0.108664\n",
      "[PREDATOR] Epoch 89 | Train Loss: 0.082192 | Val Loss: 0.124448\n",
      "[PREDATOR] Epoch 90 | Train Loss: 0.077119 | Val Loss: 0.173971\n",
      "[PREDATOR] Epoch 91 | Train Loss: 0.068153 | Val Loss: 0.192438\n",
      "[PREDATOR] Epoch 92 | Train Loss: 0.072874 | Val Loss: 0.160235\n",
      "[PREDATOR] Epoch 93 | Train Loss: 0.069448 | Val Loss: 0.123168\n",
      "[PREDATOR] Epoch 94 | Train Loss: 0.063112 | Val Loss: 0.159557\n",
      "[PREDATOR] Epoch 95 | Train Loss: 0.066375 | Val Loss: 0.097539\n",
      "[PREDATOR] Epoch 96 | Train Loss: 0.060324 | Val Loss: 0.101416\n",
      "[PREDATOR] Epoch 97 | Train Loss: 0.064102 | Val Loss: 0.108446\n",
      "[PREDATOR] Epoch 98 | Train Loss: 0.066190 | Val Loss: 0.121720\n",
      "[PREDATOR] Epoch 99 | Train Loss: 0.055243 | Val Loss: 0.110314\n",
      "[PREDATOR] Epoch 100 | Train Loss: 0.059223 | Val Loss: 0.111143\n",
      "[PREDATOR] Epoch 101 | Train Loss: 0.057994 | Val Loss: 0.118046\n",
      "[PREDATOR] Epoch 102 | Train Loss: 0.063607 | Val Loss: 0.102495\n",
      "[PREDATOR] Epoch 103 | Train Loss: 0.056489 | Val Loss: 0.113181\n",
      "[PREDATOR] Epoch 104 | Train Loss: 0.049234 | Val Loss: 0.127276\n",
      "[PREDATOR] Epoch 105 | Train Loss: 0.055217 | Val Loss: 0.115326\n",
      "[PREDATOR] Epoch 106 | Train Loss: 0.052927 | Val Loss: 0.129231\n",
      "[PREDATOR] Epoch 107 | Train Loss: 0.051249 | Val Loss: 0.121691\n",
      "[PREDATOR] Epoch 108 | Train Loss: 0.048375 | Val Loss: 0.112987\n",
      "[PREDATOR] Epoch 109 | Train Loss: 0.053387 | Val Loss: 0.145706\n",
      "[PREDATOR] Epoch 110 | Train Loss: 0.047617 | Val Loss: 0.108742\n",
      "[PREDATOR] Epoch 111 | Train Loss: 0.048535 | Val Loss: 0.112912\n",
      "[PREDATOR] Epoch 112 | Train Loss: 0.042915 | Val Loss: 0.104630\n",
      "[PREDATOR] Epoch 113 | Train Loss: 0.045273 | Val Loss: 0.096218\n",
      "[PREDATOR] Epoch 114 | Train Loss: 0.043793 | Val Loss: 0.125272\n",
      "[PREDATOR] Epoch 115 | Train Loss: 0.044714 | Val Loss: 0.081794\n",
      "[PREDATOR] Epoch 116 | Train Loss: 0.049876 | Val Loss: 0.131904\n",
      "[PREDATOR] Epoch 117 | Train Loss: 0.048893 | Val Loss: 0.079832\n",
      "[PREDATOR] Epoch 118 | Train Loss: 0.048102 | Val Loss: 0.113923\n",
      "[PREDATOR] Epoch 119 | Train Loss: 0.043228 | Val Loss: 0.078491\n",
      "[PREDATOR] Epoch 120 | Train Loss: 0.037497 | Val Loss: 0.086252\n",
      "[PREDATOR] Epoch 121 | Train Loss: 0.033817 | Val Loss: 0.099879\n",
      "[PREDATOR] Epoch 122 | Train Loss: 0.036148 | Val Loss: 0.078920\n",
      "[PREDATOR] Epoch 123 | Train Loss: 0.034632 | Val Loss: 0.092004\n",
      "[PREDATOR] Epoch 124 | Train Loss: 0.033512 | Val Loss: 0.076912\n",
      "[PREDATOR] Epoch 125 | Train Loss: 0.031972 | Val Loss: 0.085369\n",
      "[PREDATOR] Epoch 126 | Train Loss: 0.031372 | Val Loss: 0.096575\n",
      "[PREDATOR] Epoch 127 | Train Loss: 0.033408 | Val Loss: 0.068364\n",
      "[PREDATOR] Epoch 128 | Train Loss: 0.038641 | Val Loss: 0.116923\n",
      "[PREDATOR] Epoch 129 | Train Loss: 0.044999 | Val Loss: 0.074477\n",
      "[PREDATOR] Epoch 130 | Train Loss: 0.054872 | Val Loss: 0.108701\n",
      "[PREDATOR] Epoch 131 | Train Loss: 0.037780 | Val Loss: 0.068668\n",
      "[PREDATOR] Epoch 132 | Train Loss: 0.025597 | Val Loss: 0.060877\n",
      "[PREDATOR] Epoch 133 | Train Loss: 0.035172 | Val Loss: 0.108051\n",
      "[PREDATOR] Epoch 134 | Train Loss: 0.033786 | Val Loss: 0.067857\n",
      "[PREDATOR] Epoch 135 | Train Loss: 0.026358 | Val Loss: 0.064444\n",
      "[PREDATOR] Epoch 136 | Train Loss: 0.026699 | Val Loss: 0.088182\n",
      "[PREDATOR] Epoch 137 | Train Loss: 0.027626 | Val Loss: 0.061156\n",
      "[PREDATOR] Epoch 138 | Train Loss: 0.023378 | Val Loss: 0.057527\n",
      "[PREDATOR] Epoch 139 | Train Loss: 0.022588 | Val Loss: 0.075857\n",
      "[PREDATOR] Epoch 140 | Train Loss: 0.024695 | Val Loss: 0.059132\n",
      "[PREDATOR] Epoch 141 | Train Loss: 0.020081 | Val Loss: 0.063107\n",
      "[PREDATOR] Epoch 142 | Train Loss: 0.019892 | Val Loss: 0.089859\n",
      "[PREDATOR] Epoch 143 | Train Loss: 0.024093 | Val Loss: 0.057712\n",
      "[PREDATOR] Epoch 144 | Train Loss: 0.023579 | Val Loss: 0.065511\n",
      "[PREDATOR] Epoch 145 | Train Loss: 0.017839 | Val Loss: 0.059736\n",
      "[PREDATOR] Epoch 146 | Train Loss: 0.018865 | Val Loss: 0.052815\n",
      "[PREDATOR] Epoch 147 | Train Loss: 0.018467 | Val Loss: 0.068211\n",
      "[PREDATOR] Epoch 148 | Train Loss: 0.015788 | Val Loss: 0.057914\n",
      "[PREDATOR] Epoch 149 | Train Loss: 0.014925 | Val Loss: 0.060601\n",
      "[PREDATOR] Epoch 150 | Train Loss: 0.014861 | Val Loss: 0.071683\n",
      "[PREDATOR] Epoch 151 | Train Loss: 0.015674 | Val Loss: 0.047709\n",
      "[PREDATOR] Epoch 152 | Train Loss: 0.019067 | Val Loss: 0.074297\n",
      "[PREDATOR] Epoch 153 | Train Loss: 0.020041 | Val Loss: 0.042248\n",
      "[PREDATOR] Epoch 154 | Train Loss: 0.016604 | Val Loss: 0.056226\n",
      "[PREDATOR] Epoch 155 | Train Loss: 0.011536 | Val Loss: 0.065844\n",
      "[PREDATOR] Epoch 156 | Train Loss: 0.011938 | Val Loss: 0.056535\n",
      "[PREDATOR] Epoch 157 | Train Loss: 0.015245 | Val Loss: 0.078616\n",
      "[PREDATOR] Epoch 158 | Train Loss: 0.017675 | Val Loss: 0.065334\n",
      "[PREDATOR] Epoch 159 | Train Loss: 0.017875 | Val Loss: 0.073012\n",
      "[PREDATOR] Epoch 160 | Train Loss: 0.014458 | Val Loss: 0.056325\n",
      "[PREDATOR] Epoch 161 | Train Loss: 0.008650 | Val Loss: 0.053792\n",
      "[PREDATOR] Epoch 162 | Train Loss: 0.010989 | Val Loss: 0.086857\n",
      "[PREDATOR] Epoch 163 | Train Loss: 0.017304 | Val Loss: 0.063353\n",
      "[PREDATOR] Epoch 164 | Train Loss: 0.014917 | Val Loss: 0.064910\n",
      "[PREDATOR] Epoch 165 | Train Loss: 0.009369 | Val Loss: 0.067971\n",
      "[PREDATOR] Epoch 166 | Train Loss: 0.008674 | Val Loss: 0.064864\n",
      "[PREDATOR] Epoch 167 | Train Loss: 0.010941 | Val Loss: 0.075145\n",
      "[PREDATOR] Epoch 168 | Train Loss: 0.008035 | Val Loss: 0.066987\n",
      "[PREDATOR] Epoch 169 | Train Loss: 0.006321 | Val Loss: 0.070026\n",
      "[PREDATOR] Epoch 170 | Train Loss: 0.010096 | Val Loss: 0.081020\n",
      "[PREDATOR] Epoch 171 | Train Loss: 0.011960 | Val Loss: 0.068553\n",
      "[PREDATOR] Epoch 172 | Train Loss: 0.007172 | Val Loss: 0.071410\n",
      "[PREDATOR] Epoch 173 | Train Loss: 0.007985 | Val Loss: 0.091759\n",
      "[PREDATOR] Epoch 174 | Train Loss: 0.013993 | Val Loss: 0.082319\n",
      "[PREDATOR] Epoch 175 | Train Loss: 0.012189 | Val Loss: 0.071349\n",
      "[PREDATOR] Early stopping triggered (Patience=100).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_policy, pred_logs = pretrain_policy_with_validation(pred_policy, prey_policy, expert_buffer, role='predator', val_ratio=0.2, pred_bs=64, prey_bs=2048, epochs=500, lr=1e-3, early_stopping=True, patience=100)\n",
    "torch.save(pred_policy, os.path.join(save_dir, \"bc_pred_policy.pt\"))\n",
    "\n",
    "with open(os.path.join(save_dir, \"bc_pred_logs.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(pred_logs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db63520b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 01 | Train Loss: 0.436904 | Val Loss: 0.406561 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 02 | Train Loss: 0.455366 | Val Loss: 0.408194 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 03 | Train Loss: 0.448004 | Val Loss: 0.457156 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 04 | Train Loss: 0.425453 | Val Loss: 0.448895 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 05 | Train Loss: 0.440048 | Val Loss: 0.408861 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 06 | Train Loss: 0.448868 | Val Loss: 0.437813 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0313,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 07 | Train Loss: 0.431492 | Val Loss: 0.405156 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 08 | Train Loss: 0.438932 | Val Loss: 0.398268 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 09 | Train Loss: 0.443784 | Val Loss: 0.424017 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 10 | Train Loss: 0.447200 | Val Loss: 0.403835 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 11 | Train Loss: 0.462274 | Val Loss: 0.449983 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 12 | Train Loss: 0.441144 | Val Loss: 0.422549 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 13 | Train Loss: 0.448750 | Val Loss: 0.429894 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 14 | Train Loss: 0.441307 | Val Loss: 0.431088 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 15 | Train Loss: 0.437921 | Val Loss: 0.440441 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 16 | Train Loss: 0.449159 | Val Loss: 0.435435 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 17 | Train Loss: 0.480714 | Val Loss: 0.460234 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 18 | Train Loss: 0.434644 | Val Loss: 0.424772 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 19 | Train Loss: 0.475654 | Val Loss: 0.410498 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 20 | Train Loss: 0.444219 | Val Loss: 0.439196 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 21 | Train Loss: 0.445970 | Val Loss: 0.406594 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 22 | Train Loss: 0.451782 | Val Loss: 0.417930 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 23 | Train Loss: 0.446974 | Val Loss: 0.421144 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 24 | Train Loss: 0.437755 | Val Loss: 0.418143 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 25 | Train Loss: 0.443558 | Val Loss: 0.444662 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 26 | Train Loss: 0.449879 | Val Loss: 0.456926 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 27 | Train Loss: 0.450868 | Val Loss: 0.432075 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 28 | Train Loss: 0.449674 | Val Loss: 0.435850 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 29 | Train Loss: 0.445308 | Val Loss: 0.431923 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 30 | Train Loss: 0.445832 | Val Loss: 0.425386 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 31 | Train Loss: 0.444647 | Val Loss: 0.428830 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 32 | Train Loss: 0.465698 | Val Loss: 0.433879 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 33 | Train Loss: 0.451529 | Val Loss: 0.423520 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 34 | Train Loss: 0.422858 | Val Loss: 0.429061 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0313, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 35 | Train Loss: 0.443379 | Val Loss: 0.456932 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0313, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 36 | Train Loss: 0.470273 | Val Loss: 0.422917 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 37 | Train Loss: 0.445473 | Val Loss: 0.433901 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 38 | Train Loss: 0.444350 | Val Loss: 0.436723 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 39 | Train Loss: 0.473192 | Val Loss: 0.479890 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 40 | Train Loss: 0.467749 | Val Loss: 0.412282 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 41 | Train Loss: 0.436962 | Val Loss: 0.448494 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 42 | Train Loss: 0.448613 | Val Loss: 0.403639 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 43 | Train Loss: 0.455391 | Val Loss: 0.394994 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 44 | Train Loss: 0.436315 | Val Loss: 0.438690 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 45 | Train Loss: 0.453282 | Val Loss: 0.406672 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 46 | Train Loss: 0.445969 | Val Loss: 0.463708 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 47 | Train Loss: 0.433738 | Val Loss: 0.443823 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 48 | Train Loss: 0.447850 | Val Loss: 0.464635 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 49 | Train Loss: 0.447868 | Val Loss: 0.419099 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 50 | Train Loss: 0.450581 | Val Loss: 0.409982 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 51 | Train Loss: 0.444375 | Val Loss: 0.457507 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 52 | Train Loss: 0.466241 | Val Loss: 0.436001 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 53 | Train Loss: 0.448311 | Val Loss: 0.441973 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 54 | Train Loss: 0.446468 | Val Loss: 0.428165 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0313,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 55 | Train Loss: 0.449685 | Val Loss: 0.432664 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 56 | Train Loss: 0.446460 | Val Loss: 0.423272 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 57 | Train Loss: 0.457590 | Val Loss: 0.450874 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 58 | Train Loss: 0.445424 | Val Loss: 0.440297 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 59 | Train Loss: 0.449624 | Val Loss: 0.417200 | Pred Gain: 0.031249994412064552\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 60 | Train Loss: 0.460923 | Val Loss: 0.403297 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 61 | Train Loss: 0.453207 | Val Loss: 0.470621 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 62 | Train Loss: 0.433392 | Val Loss: 0.429895 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 63 | Train Loss: 0.427270 | Val Loss: 0.433316 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0313,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 64 | Train Loss: 0.436942 | Val Loss: 0.425838 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 65 | Train Loss: 0.447920 | Val Loss: 0.441021 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 66 | Train Loss: 0.458966 | Val Loss: 0.407884 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0313, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 67 | Train Loss: 0.447012 | Val Loss: 0.426589 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 68 | Train Loss: 0.455232 | Val Loss: 0.424601 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 69 | Train Loss: 0.433464 | Val Loss: 0.421779 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 70 | Train Loss: 0.445618 | Val Loss: 0.422078 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 71 | Train Loss: 0.452689 | Val Loss: 0.430798 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 72 | Train Loss: 0.445543 | Val Loss: 0.427993 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 73 | Train Loss: 0.436907 | Val Loss: 0.467907 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 74 | Train Loss: 0.442433 | Val Loss: 0.413799 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 75 | Train Loss: 0.441620 | Val Loss: 0.421594 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 76 | Train Loss: 0.427651 | Val Loss: 0.460844 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 77 | Train Loss: 0.433326 | Val Loss: 0.419514 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 78 | Train Loss: 0.452742 | Val Loss: 0.428106 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 79 | Train Loss: 0.446127 | Val Loss: 0.420297 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 80 | Train Loss: 0.448115 | Val Loss: 0.424880 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 81 | Train Loss: 0.462518 | Val Loss: 0.424348 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 82 | Train Loss: 0.445577 | Val Loss: 0.402519 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 83 | Train Loss: 0.439305 | Val Loss: 0.407098 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 84 | Train Loss: 0.436193 | Val Loss: 0.442496 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 85 | Train Loss: 0.443686 | Val Loss: 0.431717 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 86 | Train Loss: 0.456396 | Val Loss: 0.445958 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 87 | Train Loss: 0.442057 | Val Loss: 0.439799 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 88 | Train Loss: 0.432201 | Val Loss: 0.442712 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 89 | Train Loss: 0.466035 | Val Loss: 0.422384 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 90 | Train Loss: 0.445428 | Val Loss: 0.439613 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 91 | Train Loss: 0.423769 | Val Loss: 0.453698 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 92 | Train Loss: 0.437712 | Val Loss: 0.460905 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 93 | Train Loss: 0.450428 | Val Loss: 0.418836 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 94 | Train Loss: 0.450129 | Val Loss: 0.435023 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 95 | Train Loss: 0.453363 | Val Loss: 0.459509 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 96 | Train Loss: 0.434849 | Val Loss: 0.434663 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 97 | Train Loss: 0.436206 | Val Loss: 0.437083 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 98 | Train Loss: 0.456249 | Val Loss: 0.432739 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 99 | Train Loss: 0.451553 | Val Loss: 0.443300 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 100 | Train Loss: 0.457431 | Val Loss: 0.426176 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 101 | Train Loss: 0.438923 | Val Loss: 0.462522 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 102 | Train Loss: 0.444874 | Val Loss: 0.445325 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0313, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 103 | Train Loss: 0.439531 | Val Loss: 0.424104 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 104 | Train Loss: 0.456641 | Val Loss: 0.447615 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 105 | Train Loss: 0.447639 | Val Loss: 0.388298 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 106 | Train Loss: 0.446187 | Val Loss: 0.449611 | Pred Gain: 0.031249994412064552\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 107 | Train Loss: 0.459371 | Val Loss: 0.470012 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 108 | Train Loss: 0.455761 | Val Loss: 0.433304 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 109 | Train Loss: 0.455647 | Val Loss: 0.432282 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 110 | Train Loss: 0.447131 | Val Loss: 0.423125 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 111 | Train Loss: 0.441050 | Val Loss: 0.402738 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 112 | Train Loss: 0.450205 | Val Loss: 0.408193 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 113 | Train Loss: 0.449944 | Val Loss: 0.425499 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 114 | Train Loss: 0.450333 | Val Loss: 0.451083 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 115 | Train Loss: 0.437914 | Val Loss: 0.455536 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 116 | Train Loss: 0.470103 | Val Loss: 0.436038 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0313, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 117 | Train Loss: 0.449320 | Val Loss: 0.442274 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 118 | Train Loss: 0.440832 | Val Loss: 0.446815 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 119 | Train Loss: 0.447594 | Val Loss: 0.429208 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 120 | Train Loss: 0.453939 | Val Loss: 0.425309 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 121 | Train Loss: 0.460298 | Val Loss: 0.396916 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 122 | Train Loss: 0.459043 | Val Loss: 0.423298 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 123 | Train Loss: 0.445535 | Val Loss: 0.418307 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 124 | Train Loss: 0.452276 | Val Loss: 0.419875 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0313, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 125 | Train Loss: 0.444670 | Val Loss: 0.414278 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0313, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 126 | Train Loss: 0.458634 | Val Loss: 0.415730 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 127 | Train Loss: 0.439673 | Val Loss: 0.444556 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 128 | Train Loss: 0.448746 | Val Loss: 0.423604 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 129 | Train Loss: 0.440112 | Val Loss: 0.397512 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 130 | Train Loss: 0.447859 | Val Loss: 0.440729 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 131 | Train Loss: 0.449497 | Val Loss: 0.418591 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0313,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 132 | Train Loss: 0.443603 | Val Loss: 0.488286 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 133 | Train Loss: 0.446721 | Val Loss: 0.412457 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 134 | Train Loss: 0.435924 | Val Loss: 0.412097 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 135 | Train Loss: 0.447195 | Val Loss: 0.435529 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 136 | Train Loss: 0.438896 | Val Loss: 0.425927 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 137 | Train Loss: 0.445261 | Val Loss: 0.410553 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 138 | Train Loss: 0.454311 | Val Loss: 0.412555 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 139 | Train Loss: 0.435785 | Val Loss: 0.430291 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 140 | Train Loss: 0.444279 | Val Loss: 0.432601 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 141 | Train Loss: 0.453257 | Val Loss: 0.450370 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 142 | Train Loss: 0.448254 | Val Loss: 0.423160 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 143 | Train Loss: 0.455962 | Val Loss: 0.457216 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0313,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 144 | Train Loss: 0.443050 | Val Loss: 0.436391 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 145 | Train Loss: 0.442162 | Val Loss: 0.448461 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0313, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 146 | Train Loss: 0.430567 | Val Loss: 0.419359 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 147 | Train Loss: 0.452912 | Val Loss: 0.428814 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0313, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 148 | Train Loss: 0.434471 | Val Loss: 0.432934 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 149 | Train Loss: 0.422796 | Val Loss: 0.447862 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 150 | Train Loss: 0.442788 | Val Loss: 0.430272 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 151 | Train Loss: 0.451116 | Val Loss: 0.438533 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 152 | Train Loss: 0.450929 | Val Loss: 0.419131 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 153 | Train Loss: 0.451115 | Val Loss: 0.433411 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 154 | Train Loss: 0.443641 | Val Loss: 0.424028 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 155 | Train Loss: 0.465539 | Val Loss: 0.418951 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 156 | Train Loss: 0.448650 | Val Loss: 0.470562 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 157 | Train Loss: 0.440159 | Val Loss: 0.436053 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 158 | Train Loss: 0.456554 | Val Loss: 0.437294 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 159 | Train Loss: 0.447805 | Val Loss: 0.427634 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 160 | Train Loss: 0.447632 | Val Loss: 0.396406 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 161 | Train Loss: 0.455754 | Val Loss: 0.434203 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 162 | Train Loss: 0.425560 | Val Loss: 0.430958 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 163 | Train Loss: 0.468906 | Val Loss: 0.444169 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 164 | Train Loss: 0.455523 | Val Loss: 0.428201 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 165 | Train Loss: 0.441494 | Val Loss: 0.433827 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 166 | Train Loss: 0.442922 | Val Loss: 0.410745 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 167 | Train Loss: 0.449506 | Val Loss: 0.448494 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 168 | Train Loss: 0.453689 | Val Loss: 0.467798 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0313, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 169 | Train Loss: 0.441624 | Val Loss: 0.430242 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 170 | Train Loss: 0.454815 | Val Loss: 0.408293 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 171 | Train Loss: 0.443444 | Val Loss: 0.441825 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 172 | Train Loss: 0.442033 | Val Loss: 0.435447 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 173 | Train Loss: 0.442073 | Val Loss: 0.426259 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 174 | Train Loss: 0.437944 | Val Loss: 0.399914 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 175 | Train Loss: 0.454980 | Val Loss: 0.399074 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 176 | Train Loss: 0.447049 | Val Loss: 0.445836 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 177 | Train Loss: 0.465246 | Val Loss: 0.403159 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 178 | Train Loss: 0.453966 | Val Loss: 0.429778 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 179 | Train Loss: 0.442575 | Val Loss: 0.435233 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 180 | Train Loss: 0.445144 | Val Loss: 0.431231 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 181 | Train Loss: 0.453343 | Val Loss: 0.447205 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 182 | Train Loss: 0.438033 | Val Loss: 0.413703 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 183 | Train Loss: 0.441340 | Val Loss: 0.408912 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 184 | Train Loss: 0.448719 | Val Loss: 0.453210 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 185 | Train Loss: 0.455751 | Val Loss: 0.440130 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 186 | Train Loss: 0.443466 | Val Loss: 0.467101 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 187 | Train Loss: 0.457359 | Val Loss: 0.444147 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0313, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 188 | Train Loss: 0.428655 | Val Loss: 0.433315 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 189 | Train Loss: 0.441700 | Val Loss: 0.426553 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0313,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 190 | Train Loss: 0.444161 | Val Loss: 0.419793 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 191 | Train Loss: 0.455600 | Val Loss: 0.447768 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 192 | Train Loss: 0.440411 | Val Loss: 0.452346 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 193 | Train Loss: 0.448091 | Val Loss: 0.440288 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 194 | Train Loss: 0.439501 | Val Loss: 0.412370 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 195 | Train Loss: 0.442752 | Val Loss: 0.434772 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 196 | Train Loss: 0.453574 | Val Loss: 0.419457 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 197 | Train Loss: 0.443262 | Val Loss: 0.449845 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 198 | Train Loss: 0.451861 | Val Loss: 0.393432 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 199 | Train Loss: 0.437209 | Val Loss: 0.423487 | Pred Gain: 0.031249994412064552\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 200 | Train Loss: 0.468169 | Val Loss: 0.376998 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 201 | Train Loss: 0.444023 | Val Loss: 0.413905 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 202 | Train Loss: 0.443644 | Val Loss: 0.459709 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 203 | Train Loss: 0.456451 | Val Loss: 0.466812 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 204 | Train Loss: 0.449261 | Val Loss: 0.476662 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 205 | Train Loss: 0.443777 | Val Loss: 0.431603 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 206 | Train Loss: 0.449477 | Val Loss: 0.434287 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 207 | Train Loss: 0.436639 | Val Loss: 0.452000 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 208 | Train Loss: 0.443249 | Val Loss: 0.443894 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 209 | Train Loss: 0.443560 | Val Loss: 0.468431 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 210 | Train Loss: 0.445855 | Val Loss: 0.421735 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 211 | Train Loss: 0.443555 | Val Loss: 0.431211 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 212 | Train Loss: 0.449233 | Val Loss: 0.426632 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 213 | Train Loss: 0.449618 | Val Loss: 0.447297 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 214 | Train Loss: 0.447386 | Val Loss: 0.439651 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 215 | Train Loss: 0.428855 | Val Loss: 0.431501 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 216 | Train Loss: 0.430960 | Val Loss: 0.437322 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 217 | Train Loss: 0.451476 | Val Loss: 0.410107 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0313, 0.0313, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 218 | Train Loss: 0.437927 | Val Loss: 0.410834 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0313, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 219 | Train Loss: 0.448648 | Val Loss: 0.453679 | Pred Gain: 0.0312500074505806\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 220 | Train Loss: 0.444908 | Val Loss: 0.369014 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 221 | Train Loss: 0.448126 | Val Loss: 0.414820 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 222 | Train Loss: 0.462283 | Val Loss: 0.435841 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 223 | Train Loss: 0.448776 | Val Loss: 0.417096 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 224 | Train Loss: 0.447287 | Val Loss: 0.437759 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 225 | Train Loss: 0.436469 | Val Loss: 0.428141 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0313, 0.0313, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 226 | Train Loss: 0.442915 | Val Loss: 0.429829 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 227 | Train Loss: 0.439695 | Val Loss: 0.413216 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 228 | Train Loss: 0.461554 | Val Loss: 0.434712 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 229 | Train Loss: 0.433128 | Val Loss: 0.438671 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 230 | Train Loss: 0.436117 | Val Loss: 0.415578 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 231 | Train Loss: 0.437757 | Val Loss: 0.423522 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 232 | Train Loss: 0.459626 | Val Loss: 0.417809 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 233 | Train Loss: 0.441645 | Val Loss: 0.436142 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 234 | Train Loss: 0.451639 | Val Loss: 0.423437 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 235 | Train Loss: 0.441463 | Val Loss: 0.447429 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 236 | Train Loss: 0.435854 | Val Loss: 0.406089 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 237 | Train Loss: 0.445274 | Val Loss: 0.419874 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 238 | Train Loss: 0.440863 | Val Loss: 0.481711 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 239 | Train Loss: 0.443978 | Val Loss: 0.409486 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0313, 0.0313, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 240 | Train Loss: 0.422409 | Val Loss: 0.422816 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0313, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 241 | Train Loss: 0.417653 | Val Loss: 0.452662 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 242 | Train Loss: 0.447586 | Val Loss: 0.440670 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 243 | Train Loss: 0.427069 | Val Loss: 0.435478 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 244 | Train Loss: 0.455686 | Val Loss: 0.438970 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 245 | Train Loss: 0.429137 | Val Loss: 0.441627 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 246 | Train Loss: 0.426973 | Val Loss: 0.452469 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 247 | Train Loss: 0.424382 | Val Loss: 0.413625 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 248 | Train Loss: 0.428534 | Val Loss: 0.437612 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 249 | Train Loss: 0.434702 | Val Loss: 0.427722 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0313, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 250 | Train Loss: 0.447255 | Val Loss: 0.419107 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 251 | Train Loss: 0.451861 | Val Loss: 0.408377 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 252 | Train Loss: 0.450897 | Val Loss: 0.422452 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 253 | Train Loss: 0.456520 | Val Loss: 0.459289 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 254 | Train Loss: 0.459107 | Val Loss: 0.410366 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 255 | Train Loss: 0.442421 | Val Loss: 0.412275 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 256 | Train Loss: 0.424621 | Val Loss: 0.448206 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 257 | Train Loss: 0.447349 | Val Loss: 0.430498 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 258 | Train Loss: 0.441964 | Val Loss: 0.459682 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 259 | Train Loss: 0.451889 | Val Loss: 0.446303 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 260 | Train Loss: 0.460631 | Val Loss: 0.440371 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 261 | Train Loss: 0.431681 | Val Loss: 0.421473 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 262 | Train Loss: 0.452565 | Val Loss: 0.460633 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 263 | Train Loss: 0.442278 | Val Loss: 0.443301 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 264 | Train Loss: 0.428780 | Val Loss: 0.434050 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 265 | Train Loss: 0.436306 | Val Loss: 0.428395 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 266 | Train Loss: 0.450811 | Val Loss: 0.435804 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 267 | Train Loss: 0.436707 | Val Loss: 0.448131 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 268 | Train Loss: 0.439757 | Val Loss: 0.418849 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 269 | Train Loss: 0.424785 | Val Loss: 0.397821 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 270 | Train Loss: 0.430681 | Val Loss: 0.453190 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 271 | Train Loss: 0.452221 | Val Loss: 0.441346 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 272 | Train Loss: 0.449033 | Val Loss: 0.459244 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 273 | Train Loss: 0.455660 | Val Loss: 0.449990 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0313, 0.0312,  ..., 0.0312, 0.0313, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 274 | Train Loss: 0.452237 | Val Loss: 0.442757 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 275 | Train Loss: 0.441965 | Val Loss: 0.421514 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 276 | Train Loss: 0.458127 | Val Loss: 0.401733 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0313, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 277 | Train Loss: 0.444251 | Val Loss: 0.438521 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 278 | Train Loss: 0.456655 | Val Loss: 0.439749 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 279 | Train Loss: 0.443143 | Val Loss: 0.439284 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 280 | Train Loss: 0.450186 | Val Loss: 0.433298 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0313, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 281 | Train Loss: 0.432141 | Val Loss: 0.439790 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 282 | Train Loss: 0.457389 | Val Loss: 0.454041 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 283 | Train Loss: 0.449681 | Val Loss: 0.419745 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 284 | Train Loss: 0.439622 | Val Loss: 0.456347 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 285 | Train Loss: 0.445059 | Val Loss: 0.411140 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 286 | Train Loss: 0.453171 | Val Loss: 0.418818 | Pred Gain: 0.031249994412064552\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 287 | Train Loss: 0.446127 | Val Loss: 0.444404 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 288 | Train Loss: 0.447582 | Val Loss: 0.473973 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 289 | Train Loss: 0.455521 | Val Loss: 0.426908 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 290 | Train Loss: 0.443994 | Val Loss: 0.443760 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 291 | Train Loss: 0.434836 | Val Loss: 0.461885 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 292 | Train Loss: 0.445265 | Val Loss: 0.428808 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 293 | Train Loss: 0.449415 | Val Loss: 0.463715 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 294 | Train Loss: 0.440149 | Val Loss: 0.393217 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 295 | Train Loss: 0.462185 | Val Loss: 0.408811 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 296 | Train Loss: 0.450826 | Val Loss: 0.467769 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 297 | Train Loss: 0.456076 | Val Loss: 0.420425 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 298 | Train Loss: 0.453280 | Val Loss: 0.430421 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 299 | Train Loss: 0.450854 | Val Loss: 0.459714 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 300 | Train Loss: 0.443549 | Val Loss: 0.435122 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 301 | Train Loss: 0.440280 | Val Loss: 0.445590 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 302 | Train Loss: 0.466551 | Val Loss: 0.413039 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 303 | Train Loss: 0.438990 | Val Loss: 0.426411 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 304 | Train Loss: 0.436412 | Val Loss: 0.413351 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 305 | Train Loss: 0.443974 | Val Loss: 0.407831 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 306 | Train Loss: 0.436145 | Val Loss: 0.434961 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 307 | Train Loss: 0.445152 | Val Loss: 0.429567 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 308 | Train Loss: 0.450173 | Val Loss: 0.444224 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 309 | Train Loss: 0.441785 | Val Loss: 0.466863 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 310 | Train Loss: 0.460804 | Val Loss: 0.428113 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 311 | Train Loss: 0.439746 | Val Loss: 0.448661 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 312 | Train Loss: 0.458957 | Val Loss: 0.403083 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 313 | Train Loss: 0.439350 | Val Loss: 0.414942 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 314 | Train Loss: 0.445005 | Val Loss: 0.421221 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 315 | Train Loss: 0.439001 | Val Loss: 0.434502 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 316 | Train Loss: 0.444709 | Val Loss: 0.422129 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 317 | Train Loss: 0.460931 | Val Loss: 0.446043 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 318 | Train Loss: 0.457082 | Val Loss: 0.419758 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 319 | Train Loss: 0.447118 | Val Loss: 0.480251 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 320 | Train Loss: 0.441937 | Val Loss: 0.422034 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 321 | Train Loss: 0.460861 | Val Loss: 0.424419 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 322 | Train Loss: 0.440829 | Val Loss: 0.441797 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 323 | Train Loss: 0.442667 | Val Loss: 0.445932 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 324 | Train Loss: 0.446991 | Val Loss: 0.419179 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0313, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 325 | Train Loss: 0.446902 | Val Loss: 0.426919 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 326 | Train Loss: 0.445922 | Val Loss: 0.450723 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0313, 0.0313,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 327 | Train Loss: 0.429556 | Val Loss: 0.468482 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 328 | Train Loss: 0.440732 | Val Loss: 0.447730 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 329 | Train Loss: 0.440086 | Val Loss: 0.456350 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0313, 0.0313,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 330 | Train Loss: 0.458352 | Val Loss: 0.442277 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 331 | Train Loss: 0.462746 | Val Loss: 0.427135 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 332 | Train Loss: 0.446278 | Val Loss: 0.466170 | Pred Gain: 0.0312500074505806\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 333 | Train Loss: 0.432506 | Val Loss: 0.438090 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 334 | Train Loss: 0.454674 | Val Loss: 0.436383 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 335 | Train Loss: 0.451266 | Val Loss: 0.426659 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 336 | Train Loss: 0.446550 | Val Loss: 0.409288 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0313, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 337 | Train Loss: 0.459942 | Val Loss: 0.438089 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 338 | Train Loss: 0.436356 | Val Loss: 0.439224 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 339 | Train Loss: 0.440516 | Val Loss: 0.438445 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 340 | Train Loss: 0.431191 | Val Loss: 0.448582 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 341 | Train Loss: 0.447116 | Val Loss: 0.443061 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 342 | Train Loss: 0.459206 | Val Loss: 0.437073 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 343 | Train Loss: 0.447216 | Val Loss: 0.435508 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0313, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 344 | Train Loss: 0.446719 | Val Loss: 0.430324 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 345 | Train Loss: 0.443074 | Val Loss: 0.472910 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 346 | Train Loss: 0.469982 | Val Loss: 0.471693 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 347 | Train Loss: 0.440983 | Val Loss: 0.464573 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 348 | Train Loss: 0.440246 | Val Loss: 0.469999 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 349 | Train Loss: 0.444040 | Val Loss: 0.436182 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 350 | Train Loss: 0.452224 | Val Loss: 0.496799 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 351 | Train Loss: 0.448867 | Val Loss: 0.436948 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 352 | Train Loss: 0.441675 | Val Loss: 0.470753 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 353 | Train Loss: 0.441633 | Val Loss: 0.420996 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 354 | Train Loss: 0.452550 | Val Loss: 0.442194 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 355 | Train Loss: 0.448887 | Val Loss: 0.437462 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 356 | Train Loss: 0.472845 | Val Loss: 0.439119 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 357 | Train Loss: 0.443376 | Val Loss: 0.427539 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0313, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 358 | Train Loss: 0.463393 | Val Loss: 0.438171 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 359 | Train Loss: 0.443286 | Val Loss: 0.450165 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 360 | Train Loss: 0.460650 | Val Loss: 0.448400 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0313,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 361 | Train Loss: 0.446179 | Val Loss: 0.419200 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 362 | Train Loss: 0.451456 | Val Loss: 0.418352 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 363 | Train Loss: 0.447597 | Val Loss: 0.447636 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 364 | Train Loss: 0.447233 | Val Loss: 0.417913 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 365 | Train Loss: 0.444213 | Val Loss: 0.432842 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 366 | Train Loss: 0.453328 | Val Loss: 0.411497 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 367 | Train Loss: 0.455985 | Val Loss: 0.426476 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 368 | Train Loss: 0.450399 | Val Loss: 0.439789 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 369 | Train Loss: 0.446351 | Val Loss: 0.451224 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 370 | Train Loss: 0.445446 | Val Loss: 0.438233 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 371 | Train Loss: 0.428988 | Val Loss: 0.438418 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 372 | Train Loss: 0.440908 | Val Loss: 0.410229 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 373 | Train Loss: 0.454566 | Val Loss: 0.406033 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 374 | Train Loss: 0.447486 | Val Loss: 0.432927 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 375 | Train Loss: 0.446890 | Val Loss: 0.435985 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 376 | Train Loss: 0.441981 | Val Loss: 0.432435 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 377 | Train Loss: 0.444995 | Val Loss: 0.420964 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 378 | Train Loss: 0.447236 | Val Loss: 0.403181 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 379 | Train Loss: 0.450001 | Val Loss: 0.431036 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 380 | Train Loss: 0.440305 | Val Loss: 0.423780 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0313, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 381 | Train Loss: 0.454813 | Val Loss: 0.472558 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 382 | Train Loss: 0.462598 | Val Loss: 0.419386 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 383 | Train Loss: 0.411539 | Val Loss: 0.452410 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 384 | Train Loss: 0.435143 | Val Loss: 0.431015 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 385 | Train Loss: 0.468690 | Val Loss: 0.433711 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 386 | Train Loss: 0.426592 | Val Loss: 0.430566 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 387 | Train Loss: 0.456633 | Val Loss: 0.447727 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 388 | Train Loss: 0.450253 | Val Loss: 0.448139 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 389 | Train Loss: 0.447695 | Val Loss: 0.461519 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 390 | Train Loss: 0.452255 | Val Loss: 0.440115 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 391 | Train Loss: 0.461555 | Val Loss: 0.415760 | Pred Gain: 0.031249994412064552\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 392 | Train Loss: 0.443918 | Val Loss: 0.463698 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 393 | Train Loss: 0.445360 | Val Loss: 0.483000 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 394 | Train Loss: 0.463388 | Val Loss: 0.452189 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 395 | Train Loss: 0.445519 | Val Loss: 0.436414 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 396 | Train Loss: 0.447716 | Val Loss: 0.431853 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 397 | Train Loss: 0.456204 | Val Loss: 0.434395 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 398 | Train Loss: 0.449435 | Val Loss: 0.446512 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 399 | Train Loss: 0.457429 | Val Loss: 0.411557 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 400 | Train Loss: 0.457326 | Val Loss: 0.401480 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 401 | Train Loss: 0.445832 | Val Loss: 0.483171 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 402 | Train Loss: 0.460268 | Val Loss: 0.447143 | Pred Gain: 0.0312500074505806\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 403 | Train Loss: 0.430208 | Val Loss: 0.392471 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 404 | Train Loss: 0.445966 | Val Loss: 0.479706 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 405 | Train Loss: 0.467720 | Val Loss: 0.436744 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 406 | Train Loss: 0.437407 | Val Loss: 0.422367 | Pred Gain: 0.0312500074505806\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 407 | Train Loss: 0.446439 | Val Loss: 0.439871 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 408 | Train Loss: 0.451323 | Val Loss: 0.444928 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 409 | Train Loss: 0.446627 | Val Loss: 0.435005 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 410 | Train Loss: 0.448062 | Val Loss: 0.458304 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 411 | Train Loss: 0.439167 | Val Loss: 0.447730 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 412 | Train Loss: 0.446556 | Val Loss: 0.414894 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0313,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 413 | Train Loss: 0.457366 | Val Loss: 0.418506 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 414 | Train Loss: 0.449158 | Val Loss: 0.437632 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 415 | Train Loss: 0.443552 | Val Loss: 0.418389 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 416 | Train Loss: 0.450404 | Val Loss: 0.427652 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 417 | Train Loss: 0.453650 | Val Loss: 0.426317 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 418 | Train Loss: 0.451779 | Val Loss: 0.421666 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 419 | Train Loss: 0.439698 | Val Loss: 0.425669 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 420 | Train Loss: 0.427123 | Val Loss: 0.429085 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 421 | Train Loss: 0.437283 | Val Loss: 0.404951 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 422 | Train Loss: 0.451447 | Val Loss: 0.430923 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 423 | Train Loss: 0.439588 | Val Loss: 0.445772 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 424 | Train Loss: 0.462451 | Val Loss: 0.456436 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 425 | Train Loss: 0.442881 | Val Loss: 0.429425 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 426 | Train Loss: 0.452523 | Val Loss: 0.450346 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 427 | Train Loss: 0.440906 | Val Loss: 0.418109 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 428 | Train Loss: 0.421749 | Val Loss: 0.400791 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 429 | Train Loss: 0.444976 | Val Loss: 0.399113 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 430 | Train Loss: 0.445524 | Val Loss: 0.444652 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 431 | Train Loss: 0.441400 | Val Loss: 0.441299 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0313, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 432 | Train Loss: 0.443263 | Val Loss: 0.390582 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 433 | Train Loss: 0.437465 | Val Loss: 0.422853 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 434 | Train Loss: 0.437288 | Val Loss: 0.420544 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 435 | Train Loss: 0.440729 | Val Loss: 0.450960 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 436 | Train Loss: 0.445426 | Val Loss: 0.429663 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 437 | Train Loss: 0.459546 | Val Loss: 0.419402 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 438 | Train Loss: 0.458548 | Val Loss: 0.430895 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 439 | Train Loss: 0.439749 | Val Loss: 0.385763 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 440 | Train Loss: 0.453641 | Val Loss: 0.435848 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 441 | Train Loss: 0.441564 | Val Loss: 0.444842 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 442 | Train Loss: 0.436327 | Val Loss: 0.448193 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 443 | Train Loss: 0.461141 | Val Loss: 0.415422 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 444 | Train Loss: 0.441968 | Val Loss: 0.433060 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 445 | Train Loss: 0.464302 | Val Loss: 0.436706 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 446 | Train Loss: 0.476764 | Val Loss: 0.487326 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 447 | Train Loss: 0.451911 | Val Loss: 0.417839 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 448 | Train Loss: 0.454675 | Val Loss: 0.444565 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 449 | Train Loss: 0.444508 | Val Loss: 0.400954 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 450 | Train Loss: 0.437412 | Val Loss: 0.436260 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 451 | Train Loss: 0.434176 | Val Loss: 0.447677 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 452 | Train Loss: 0.433883 | Val Loss: 0.410065 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 453 | Train Loss: 0.440311 | Val Loss: 0.455136 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 454 | Train Loss: 0.449138 | Val Loss: 0.432423 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 455 | Train Loss: 0.446247 | Val Loss: 0.422201 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 456 | Train Loss: 0.441276 | Val Loss: 0.466273 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 457 | Train Loss: 0.436707 | Val Loss: 0.426164 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 458 | Train Loss: 0.437384 | Val Loss: 0.404731 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 459 | Train Loss: 0.448827 | Val Loss: 0.420016 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 460 | Train Loss: 0.443764 | Val Loss: 0.412712 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 461 | Train Loss: 0.456532 | Val Loss: 0.438457 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 462 | Train Loss: 0.470502 | Val Loss: 0.460237 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 463 | Train Loss: 0.431325 | Val Loss: 0.430613 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 464 | Train Loss: 0.452604 | Val Loss: 0.409516 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 465 | Train Loss: 0.442048 | Val Loss: 0.454191 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 466 | Train Loss: 0.435253 | Val Loss: 0.442262 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 467 | Train Loss: 0.435084 | Val Loss: 0.409191 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 468 | Train Loss: 0.455276 | Val Loss: 0.401732 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0313],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 469 | Train Loss: 0.459494 | Val Loss: 0.446162 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 470 | Train Loss: 0.427683 | Val Loss: 0.428296 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 471 | Train Loss: 0.451053 | Val Loss: 0.456662 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 472 | Train Loss: 0.451050 | Val Loss: 0.456274 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 473 | Train Loss: 0.455920 | Val Loss: 0.390690 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 474 | Train Loss: 0.435906 | Val Loss: 0.459157 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 475 | Train Loss: 0.451355 | Val Loss: 0.456610 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 476 | Train Loss: 0.444658 | Val Loss: 0.448716 | Pred Gain: 0.03124999813735485\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 477 | Train Loss: 0.451932 | Val Loss: 0.432636 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 478 | Train Loss: 0.456218 | Val Loss: 0.465646 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 479 | Train Loss: 0.431067 | Val Loss: 0.476501 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 480 | Train Loss: 0.450518 | Val Loss: 0.407873 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 481 | Train Loss: 0.468788 | Val Loss: 0.484100 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 482 | Train Loss: 0.448126 | Val Loss: 0.429421 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 483 | Train Loss: 0.441658 | Val Loss: 0.437899 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 484 | Train Loss: 0.436980 | Val Loss: 0.443112 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 485 | Train Loss: 0.429590 | Val Loss: 0.433339 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0313, 0.0313, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 486 | Train Loss: 0.447716 | Val Loss: 0.447266 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 487 | Train Loss: 0.438468 | Val Loss: 0.454263 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0313,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 488 | Train Loss: 0.446115 | Val Loss: 0.464985 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 489 | Train Loss: 0.439096 | Val Loss: 0.463523 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 490 | Train Loss: 0.450702 | Val Loss: 0.441640 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0313,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 491 | Train Loss: 0.453659 | Val Loss: 0.427615 | Pred Gain: 0.0312500074505806\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 492 | Train Loss: 0.451158 | Val Loss: 0.446276 | Pred Gain: 0.0312499962747097\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 493 | Train Loss: 0.439198 | Val Loss: 0.438346 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 494 | Train Loss: 0.437913 | Val Loss: 0.423781 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 495 | Train Loss: 0.439076 | Val Loss: 0.443163 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 496 | Train Loss: 0.442184 | Val Loss: 0.459133 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 497 | Train Loss: 0.434638 | Val Loss: 0.399296 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0313, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 498 | Train Loss: 0.433593 | Val Loss: 0.420298 | Pred Gain: 0.03125\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0313, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 499 | Train Loss: 0.445722 | Val Loss: 0.432281 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0313, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 500 | Train Loss: 0.447880 | Val Loss: 0.463778 | Pred Gain: 0.0312500037252903\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0313, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 501 | Train Loss: 0.436961 | Val Loss: 0.424347 | Pred Gain: 0.03125\n",
      "tensor([0.0312, 0.0312, 0.0312,  ..., 0.0312, 0.0312, 0.0312],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "[PREY] Epoch 502 | Train Loss: 0.435822 | Val Loss: 0.442527 | Pred Gain: 0.03124999813735485\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m prey_policy, prey_logs \u001b[38;5;241m=\u001b[39m \u001b[43mpretrain_policy_with_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprey_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpert_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprey\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_bs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprey_bs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(prey_policy, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbc_prey_policy.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbc_prey_logs.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\janni\\OneDrive\\Dokumente\\Privat\\Bildung\\M. Sc. Social and Economic Data Science\\4. Semester\\Master Thesis\\Code\\notebooks\\utils\\train_utils.py:283\u001b[0m, in \u001b[0;36mpretrain_policy_with_validation\u001b[1;34m(policy, pred_policy, expert_buffer, role, val_ratio, pred_bs, prey_bs, epochs, lr, device, early_stopping, patience)\u001b[0m\n\u001b[0;32m    281\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(actions_pred, batch_actions)\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 283\u001b[0m     actions_pred, mu_pred, sigma_pred, weights_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpred_policy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m     actions_prey, mu_prey, sigma_prey, weights_prey, pred_gain \u001b[38;5;241m=\u001b[39m policy\u001b[38;5;241m.\u001b[39mforward(batch_states, weights_pred)\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28mprint\u001b[39m(pred_gain)\n",
      "File \u001b[1;32mc:\\Users\\janni\\OneDrive\\Dokumente\\Privat\\Bildung\\M. Sc. Social and Economic Data Science\\4. Semester\\Master Thesis\\Code\\notebooks\\models\\PredatorPolicy.py:32\u001b[0m, in \u001b[0;36mPredatorPolicy.forward\u001b[1;34m(self, states)\u001b[0m\n\u001b[0;32m     29\u001b[0m actions \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mtanh(sampled_action) \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mpi)\u001b[38;5;241m.\u001b[39mview(agents, neigh) \u001b[38;5;66;03m# Value Range [-pi:pi]\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Attention Weights\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m weight_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates_flat\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(agents, neigh)\n\u001b[0;32m     33\u001b[0m weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(weight_logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Action Calculation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\GAIL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\GAIL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\janni\\OneDrive\\Dokumente\\Privat\\Bildung\\M. Sc. Social and Economic Data Science\\4. Semester\\Master Thesis\\Code\\notebooks\\models\\ModularNetworks.py:42\u001b[0m, in \u001b[0;36mAttention.forward\u001b[1;34m(self, states)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, states):\n\u001b[0;32m     41\u001b[0m     weight \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(states))\n\u001b[1;32m---> 42\u001b[0m     weight \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     43\u001b[0m     weight \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(weight))\n\u001b[0;32m     44\u001b[0m     weight \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc4(weight))\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\GAIL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\GAIL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\GAIL\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prey_policy, prey_logs = pretrain_policy_with_validation(prey_policy, pred_policy, expert_buffer, role='prey', val_ratio=0.2, pred_bs=64, prey_bs=2048, epochs=10000, lr=1e-3, early_stopping=True, patience=20)\n",
    "torch.save(prey_policy, os.path.join(save_dir, \"bc_prey_policy.pt\"))\n",
    "\n",
    "with open(os.path.join(save_dir, \"bc_prey_logs.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(prey_logs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae33e2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to end simulation.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 9, got 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m positions \u001b[38;5;241m=\u001b[39m start_frame_pool\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m env\u001b[38;5;241m.\u001b[39mreset(options\u001b[38;5;241m=\u001b[39mpositions)\n\u001b[1;32m----> 4\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mrun_policies\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprey_policy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janni\\OneDrive\\Dokumente\\Privat\\Bildung\\M. Sc. Social and Economic Data Science\\4. Semester\\Master Thesis\\Code\\notebooks\\utils\\eval_utils.py:243\u001b[0m, in \u001b[0;36mrun_policies\u001b[1;34m(env, pred_policy, prey_policy, render)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    242\u001b[0m global_state \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstate()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m--> 243\u001b[0m pred_tensor, prey_tensor, xs, ys, directions, dx, dy, vxs, vys \u001b[38;5;241m=\u001b[39m get_eval_features(global_state)\n\u001b[0;32m    245\u001b[0m pred_states \u001b[38;5;241m=\u001b[39m pred_tensor[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m    246\u001b[0m action_pred, mu_pred, sigma_pred, weights_pred \u001b[38;5;241m=\u001b[39m pred_policy\u001b[38;5;241m.\u001b[39mforward(pred_states)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 9, got 8)"
     ]
    }
   ],
   "source": [
    "env = parallel_env(use_walls=True)\n",
    "positions = start_frame_pool.sample(n=1)\n",
    "env.reset(options=positions)\n",
    "metrics = run_policies(env, pred_policy, prey_policy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAIL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
