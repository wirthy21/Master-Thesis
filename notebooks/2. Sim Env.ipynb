{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348e8b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pylab\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from math import *\n",
    "import matplotlib as mpl\n",
    "from cycler import cycler\n",
    "from numpy.linalg import *\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from models.ModularNetworks import PairwiseInteraction, Attention\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from torch.distributions import Normal\n",
    "from datetime import datetime\n",
    "\n",
    "mpl.use('TkAgg')\n",
    "from utils.couzin_utils import run_couzin_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c4f7fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModularPolicy(nn.Module):\n",
    "    def __init__(self, features=4):\n",
    "        super(ModularPolicy, self).__init__()\n",
    "\n",
    "        self.pairwise = PairwiseInteraction(features)\n",
    "        self.attention = Attention(features)\n",
    "\n",
    "    def forward(self, states, deterministic=True):\n",
    "        mu, sigma = self.pairwise(states)\n",
    "        sigma = F.softplus(sigma) + 1e-6  # ensure positivity\n",
    "\n",
    "        weights_logit = self.attention(states)\n",
    "        weights = torch.softmax(weights_logit, dim=1)\n",
    "\n",
    "        if deterministic:\n",
    "            scaled_action = torch.sigmoid(mu)\n",
    "            action = (scaled_action * weights).sum(dim=1)\n",
    "            return action\n",
    "        else:\n",
    "            eps = torch.randn_like(mu)\n",
    "            action = mu + sigma * eps\n",
    "            scaled_action = torch.sigmoid(action)\n",
    "            action = (scaled_action * weights).sum(dim=1)\n",
    "            return action # [0,1]\n",
    "        \n",
    "    def set_parameters(self, init=True):\n",
    "        if init is True:\n",
    "            for layer in self.modules():\n",
    "                if hasattr(layer, 'reset_parameters'):\n",
    "                    layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db2dff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "folder = \"2026.01.06_15.22\"\n",
    "base_dir = Path(r\"..\\data\\2. Training\\training\\VideoPredPrey - GAIL\")\n",
    "\n",
    "prey_path = base_dir / folder / \"prey_policy.pth\"\n",
    "prey_policy = ModularPolicy(features=5).to(device)\n",
    "prey_policy.load_state_dict(torch.load(prey_path))\n",
    "\n",
    "if (base_dir / folder / \"pred_policy.pth\").exists():\n",
    "    pred_path = base_dir / folder / \"pred_policy.pth\"\n",
    "    pred_policy = ModularPolicy(features=4).to(device)\n",
    "    pred_policy.load_state_dict(torch.load(pred_path))\n",
    "\n",
    "init_pool_path = rf\"..\\data\\1. Data Processing\\processed\\init_pool\\init_pool.pt\"\n",
    "init_pool = torch.load(init_pool_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c15d48f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pylab\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from math import *\n",
    "import matplotlib as mpl\n",
    "from cycler import cycler\n",
    "from numpy.linalg import *\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, agent_id, speed, area_width, area_height):\n",
    "        self.id = agent_id\n",
    "        self.pos = np.array([np.random.uniform(0, area_width),\n",
    "                             np.random.uniform(0, area_height)], dtype=np.float64)\n",
    "\n",
    "        self.theta = np.random.uniform(-np.pi, np.pi)\n",
    "        self.vel = np.array([np.cos(self.theta), np.sin(self.theta)], dtype=np.float64) * speed\n",
    "\n",
    "    def update_position(self, step_size):\n",
    "        self.pos += self.vel * step_size\n",
    "\n",
    "\n",
    "def apply_turnrate_on_theta(agent, action, speed, max_turn=np.pi):\n",
    "    dtheta = (action - 0.5) * 2.0 * max_turn\n",
    "    agent.theta = (agent.theta + dtheta + np.pi) % (2*np.pi) - np.pi\n",
    "    agent.vel = np.array([np.cos(agent.theta), np.sin(agent.theta)]) * speed\n",
    "\n",
    "\n",
    "\n",
    "def enforce_walls(agent, area_width, area_height):\n",
    "    bounced = False\n",
    "\n",
    "    if agent.pos[0] < 0:\n",
    "        agent.pos[0] = 0\n",
    "        agent.theta = np.pi - agent.theta\n",
    "        bounced = True\n",
    "    elif agent.pos[0] > area_width:\n",
    "        agent.pos[0] = area_width\n",
    "        agent.theta = np.pi - agent.theta\n",
    "        bounced = True\n",
    "\n",
    "    if agent.pos[1] < 0:\n",
    "        agent.pos[1] = 0\n",
    "        agent.theta = -agent.theta\n",
    "        bounced = True\n",
    "    elif agent.pos[1] > area_height:\n",
    "        agent.pos[1] = area_height\n",
    "        agent.theta = -agent.theta\n",
    "        bounced = True\n",
    "\n",
    "    if bounced:\n",
    "        agent.theta = (agent.theta + np.pi) % (2*np.pi) - np.pi\n",
    "        speed = float(norm(agent.vel)) \n",
    "        agent.vel = np.array([np.cos(agent.theta), np.sin(agent.theta)], dtype=np.float64) * speed\n",
    "\n",
    "\n",
    "def get_state_tensors(prey_log_step, pred_log_step, n_pred=1, \n",
    "                      area_width=50, area_height=50,\n",
    "                      prey_speed=5, pred_speed=5, max_speed_norm=15,\n",
    "                      mask=None):\n",
    "    \n",
    "    combined = np.vstack([pred_log_step, prey_log_step]).astype(np.float32)  # [N,6]\n",
    "    n_agents = combined.shape[0]\n",
    "\n",
    "    xs, ys  = combined[:, 0], combined[:, 1]\n",
    "    vxs, vys = combined[:, 2], combined[:, 3]\n",
    "    dir_x, dir_y = combined[:, 4], combined[:, 5]\n",
    "\n",
    "    cos_t = dir_x.astype(np.float32)\n",
    "    sin_t = dir_y.astype(np.float32)\n",
    "\n",
    "    xs_scaled = xs / float(area_width)\n",
    "    ys_scaled = ys / float(area_height)\n",
    "\n",
    "    dx = xs_scaled[None, :] - xs_scaled[:, None]\n",
    "    dy = ys_scaled[None, :] - ys_scaled[:, None]\n",
    "\n",
    "    rel_vx = cos_t[:, None] * vxs[None, :] + sin_t[:, None] * vys[None, :]\n",
    "    rel_vy = -sin_t[:, None] * vxs[None, :] + cos_t[:, None] * vys[None, :]\n",
    "\n",
    "    speed = max_speed_norm # same scaling as expert\n",
    "    rel_vx = np.clip(rel_vx, -speed, speed) / speed\n",
    "    rel_vy = np.clip(rel_vy, -speed, speed) / speed\n",
    "\n",
    "    features = np.stack([dx, dy, rel_vx, rel_vy], axis=-1).astype(np.float32)\n",
    "    neigh = features[mask].reshape(n_agents, n_agents-1, 4)\n",
    "\n",
    "    tensor = torch.from_numpy(neigh)   # already float32\n",
    "\n",
    "    pred_tensor = tensor[:n_pred]\n",
    "    prey_tensor = tensor[n_pred:]\n",
    "\n",
    "    if n_pred > 0:\n",
    "        agents, neighs, _ = prey_tensor.shape\n",
    "        flag = torch.zeros((agents, neighs, 1), dtype=prey_tensor.dtype, device=prey_tensor.device)\n",
    "        flag[:, :n_pred, 0] = 1\n",
    "        prey_tensor = torch.cat([flag, prey_tensor], dim=-1)\n",
    "\n",
    "    return pred_tensor, prey_tensor\n",
    "\n",
    "\n",
    "def apply_init_pool(init_pool, pred, prey, area_width=50, area_height=50, seed=None):\n",
    "    steps, agents, coordinates = init_pool.shape\n",
    "    agents = len(pred) + len(prey)\n",
    "\n",
    "    positions = init_pool[torch.randint(steps, (1,)).item(), :agents]  # [agents, 2]\n",
    "\n",
    "    positions[:, 0] *= float(area_width)\n",
    "    positions[:, 1] *= float(area_height)\n",
    "\n",
    "    center_env = torch.tensor([area_width * 0.5, area_height * 0.5], dtype=positions.dtype, device=positions.device)\n",
    "    center_pos = positions.mean(dim=0)\n",
    "    shift = center_env - center_pos\n",
    "    positions = positions + shift\n",
    "\n",
    "    # predators\n",
    "    for i in range(len(pred)):\n",
    "        pred[i].pos = positions[i].detach().cpu().numpy().astype(np.float64)\n",
    "\n",
    "    # prey\n",
    "    for i in range(len(prey)):\n",
    "        j = len(pred) + i\n",
    "        prey[i].pos = positions[j].detach().cpu().numpy().astype(np.float64)\n",
    "\n",
    "\n",
    "def run_env_simulation(prey_policy=None, pred_policy=None, \n",
    "                       n_prey=32, n_pred=1, step_size=1.0,\n",
    "                       max_steps=100, seed=None, deterministic=False,\n",
    "                       prey_speed=15, pred_speed=15, \n",
    "                       area_width=50, area_height=50, \n",
    "                       visualization='off', init_pool=None):\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed) # agent init\n",
    "        torch.manual_seed(seed) # CPU\n",
    "\n",
    "    prey_policy = deepcopy(prey_policy).to(\"cpu\")\n",
    "    pred_policy = deepcopy(pred_policy).to(\"cpu\") if pred_policy is not None else None\n",
    "\n",
    "    prey = [Agent(i, prey_speed, area_width, area_height) for i in range(n_prey)]\n",
    "    pred = [Agent(i, pred_speed, area_width, area_height) for i in range(n_pred)]\n",
    "\n",
    "    if init_pool is not None:\n",
    "        apply_init_pool(init_pool, pred, prey, area_width=area_width, area_height=area_height)\n",
    "\n",
    "    n_agents = n_prey + n_pred\n",
    "    neigh = n_agents - 1\n",
    "    prey_traj = torch.empty((max_steps, n_prey, neigh, 6), dtype=torch.float32) if n_pred > 0 else torch.empty((max_steps, n_prey, neigh, 5), dtype=torch.float32)\n",
    "    pred_traj = torch.empty((max_steps, n_pred, neigh, 5), dtype=torch.float32) if n_pred > 0 else None\n",
    "\n",
    "    if visualization == 'on':\n",
    "        prey_pos_vis = np.zeros((n_prey, 2), dtype=np.float32)\n",
    "        prey_vel_vis = np.zeros((n_prey, 2), dtype=np.float32)\n",
    "        pred_pos_vis = np.zeros((n_pred, 2), dtype=np.float32) if n_pred > 0 else None\n",
    "        pred_vel_vis = np.zeros((n_pred, 2), dtype=np.float32) if n_pred > 0 else None\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    mask = ~np.eye(n_agents, dtype=bool)\n",
    "    t = 0\n",
    "\n",
    "    while t < max_steps:\n",
    "        prey_pos_now = np.asarray([a.pos for a in prey], dtype=np.float32)  # [n_prey,2]\n",
    "        prey_vel_now = np.asarray([a.vel for a in prey], dtype=np.float32)  # [n_prey,2]\n",
    "        prey_dir = prey_vel_now / (np.linalg.norm(prey_vel_now, axis=1, keepdims=True) + 1e-12)\n",
    "        prey_log_t = np.concatenate([prey_pos_now, prey_vel_now, prey_dir], axis=1)  # [n_prey,6]\n",
    "\n",
    "        if n_pred > 0:\n",
    "            pred_pos_now = np.asarray([a.pos for a in pred], dtype=np.float32)\n",
    "            pred_vel_now = np.asarray([a.vel for a in pred], dtype=np.float32)\n",
    "            pred_dir = pred_vel_now / (np.linalg.norm(pred_vel_now, axis=1, keepdims=True) + 1e-12)\n",
    "            predator_log_t = np.concatenate([pred_pos_now, pred_vel_now, pred_dir], axis=1)\n",
    "        else:\n",
    "            predator_log_t = np.empty((0, 6), dtype=np.float32)\n",
    "\n",
    "        # --- Visualization ---\n",
    "        if visualization == 'on':\n",
    "            prey_pos_vis[:, :] = prey_pos_now\n",
    "            prey_vel_vis[:, :] = prey_vel_now\n",
    "\n",
    "            if n_pred > 0:\n",
    "                pred_pos_vis[:, :] = pred_pos_now\n",
    "                pred_vel_vis[:, :] = pred_vel_now\n",
    "\n",
    "            ax.clear()\n",
    "            pylab.quiver(\n",
    "                prey_pos_vis[:, 0], prey_pos_vis[:, 1],\n",
    "                prey_vel_vis[:, 0], prey_vel_vis[:, 1],\n",
    "                scale=120,\n",
    "                width=0.01,\n",
    "                headwidth=3,\n",
    "                headlength=3,\n",
    "                headaxislength=3,\n",
    "            )\n",
    "\n",
    "            if n_pred > 0:\n",
    "                pylab.quiver(\n",
    "                    pred_pos_vis[:, 0], pred_pos_vis[:, 1],\n",
    "                    pred_vel_vis[:, 0], pred_vel_vis[:, 1],\n",
    "                    color=\"#FF0000\",\n",
    "                    scale=120,\n",
    "                    width=0.01,\n",
    "                    headwidth=3,\n",
    "                    headlength=3,\n",
    "                    headaxislength=3,\n",
    "                )\n",
    "            ax.set_aspect('equal', 'box')\n",
    "            ax.set_xlim(0, area_width)\n",
    "            ax.set_ylim(0, area_height)\n",
    "\n",
    "            plt.pause(0.00000001)\n",
    "\n",
    "        pred_states, prey_states = get_state_tensors(prey_log_t, predator_log_t, \n",
    "                                                     n_pred=n_pred, \n",
    "                                                     area_width=area_width, area_height=area_height, \n",
    "                                                     prey_speed=prey_speed, pred_speed=pred_speed,\n",
    "                                                     mask=mask)\n",
    "\n",
    "        if n_pred > 0:\n",
    "            with torch.inference_mode():\n",
    "                pred_actions = pred_policy.forward(pred_states, deterministic=deterministic)\n",
    "                #pred_actions = torch.full_like(pred_actions, float(0.49))\n",
    "                pred_traj[t, :, :, :4] = pred_states\n",
    "                pred_traj[t, :, :, 4:] = pred_actions.unsqueeze(1).expand(-1, neigh, -1) #[1, 1, 32, 6]\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                prey_actions = prey_policy.forward(prey_states, deterministic=deterministic)\n",
    "                #prey_actions = torch.full_like(prey_actions, float(0.51))\n",
    "                prey_traj[t, :, :, :5] = prey_states\n",
    "                prey_traj[t, :, :, 5:] = prey_actions.unsqueeze(1).expand(-1, neigh, -1) #[1, 32, 32, 6]\n",
    "        else:\n",
    "            with torch.inference_mode():\n",
    "                prey_actions = prey_policy.forward(prey_states, deterministic=deterministic)\n",
    "                prey_traj[t, :, :, :4] = prey_states\n",
    "                prey_traj[t, :, :, 4:] = prey_actions.unsqueeze(1).expand(-1, neigh, -1)\n",
    "\n",
    "        prey_actions = prey_actions.squeeze(-1).detach().cpu().numpy()\n",
    "        for i, agent in enumerate(prey):\n",
    "            apply_turnrate_on_theta(agent, prey_actions[i], prey_speed)\n",
    "\n",
    "        if n_pred > 0:\n",
    "            pred_actions = pred_actions.squeeze(-1).detach().cpu().numpy()\n",
    "            for i, predator in enumerate(pred):\n",
    "                apply_turnrate_on_theta(predator, pred_actions[i], pred_speed)\n",
    "\n",
    "        for agent in prey:\n",
    "            agent.update_position(step_size=step_size)\n",
    "            enforce_walls(agent, area_width, area_height)\n",
    "\n",
    "        if n_pred > 0:\n",
    "            for predator in pred:\n",
    "                predator.update_position(step_size=step_size)\n",
    "                enforce_walls(predator, area_width, area_height)\n",
    "\n",
    "        t += 1\n",
    "\n",
    "        prey_tensor = prey_traj[:t]\n",
    "        pred_tensor = pred_traj[:t] if n_pred > 0 else None\n",
    "\n",
    "    return pred_tensor, prey_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d96b9bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_pool_path = rf\"..\\data\\1. Data Processing\\processed\\init_pool\\init_pool.pt\"\n",
    "init_pool = torch.load(init_pool_path)\n",
    "\n",
    "gen_pred_tensor, gen_prey_tensor = run_env_simulation(visualization='off', init_pool=init_pool,\n",
    "                                                      prey_policy=prey_policy, pred_policy=pred_policy, \n",
    "                                                      n_prey=32, n_pred=1, \n",
    "                                                      pred_speed=5, prey_speed=5,\n",
    "                                                      max_steps=50, step_size=3,\n",
    "                                                      area_width=2160, area_height=2160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a988593a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2.558122396469116\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for i in range(32):\n",
    "    gen_pred_tensor, gen_prey_tensor = run_env_simulation(visualization='off', init_pool=init_pool,\n",
    "                                                        prey_policy=prey_policy, pred_policy=pred_policy, \n",
    "                                                        n_prey=32, n_pred=1, \n",
    "                                                        pred_speed=5, prey_speed=5,\n",
    "                                                        max_steps=50, step_size=3,\n",
    "                                                        area_width=2160, area_height=2160)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time:\", (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f4a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def velocity_from_theta(theta, speed):\n",
    "    vx = torch.cos(theta) * speed\n",
    "    vy = torch.sin(theta) * speed\n",
    "    return torch.stack([vx, vy], dim=-1)\n",
    "\n",
    "\n",
    "def apply_turnrate(theta, action, max_turn=torch.pi):\n",
    "    dtheta = (action - 0.5) * 2.0 * max_turn\n",
    "    theta = theta + dtheta\n",
    "    return (theta + torch.pi) % (2*torch.pi) - torch.pi\n",
    "\n",
    "\n",
    "def enforce_walls(pos, theta, area_width, area_height):\n",
    "    bounced_x = (pos[..., 0] < 0) | (pos[..., 0] > area_width)\n",
    "    bounced_y = (pos[..., 1] < 0) | (pos[..., 1] > area_height)\n",
    "\n",
    "    pos[..., 0] = pos[..., 0].clamp(0.0, float(area_width))\n",
    "    pos[..., 1] = pos[..., 1].clamp(0.0, float(area_height))\n",
    "\n",
    "    theta = torch.where(bounced_x, torch.pi - theta, theta)\n",
    "    theta = torch.where(bounced_y, -theta, theta)\n",
    "\n",
    "    theta = (theta + torch.pi) % (2 * torch.pi) - torch.pi\n",
    "    return pos, theta\n",
    "\n",
    "\n",
    "def get_state_tensors(prey_log_step, pred_log_step, n_pred=1, \n",
    "                      area_width=50, area_height=50, \n",
    "                      max_speed_norm=15, neigh_idx=None):\n",
    "    \n",
    "    device = prey_log_step.device\n",
    "    combined = torch.cat([pred_log_step, prey_log_step], dim=1)\n",
    "    batch, n_agents, _ = combined.shape\n",
    "    n_neigh = n_agents - 1\n",
    "\n",
    "    xs, ys   = combined[..., 0], combined[..., 1]\n",
    "    vxs, vys = combined[..., 2], combined[..., 3]\n",
    "    cos_t, sin_t = combined[..., 4], combined[..., 5]\n",
    "\n",
    "    xs_scaled = xs / float(area_width)\n",
    "    ys_scaled = ys / float(area_height)\n",
    "\n",
    "    dx = xs_scaled.unsqueeze(2) - xs_scaled.unsqueeze(1)\n",
    "    dy = ys_scaled.unsqueeze(2) - ys_scaled.unsqueeze(1)\n",
    "\n",
    "    rel_vx = cos_t.unsqueeze(2) * vxs.unsqueeze(1) + sin_t.unsqueeze(2) * vys.unsqueeze(1)\n",
    "    rel_vy = -sin_t.unsqueeze(2) * vxs.unsqueeze(1) + cos_t.unsqueeze(2) * vys.unsqueeze(1)\n",
    "\n",
    "    speed = float(max_speed_norm)\n",
    "    rel_vx = torch.clamp(rel_vx, -speed, speed) / speed\n",
    "    rel_vy = torch.clamp(rel_vy, -speed, speed) / speed\n",
    "\n",
    "    features = torch.stack([dx, dy, rel_vx, rel_vy], dim=-1)\n",
    "\n",
    "    gather_idx = neigh_idx.view(1, n_agents, n_neigh, 1).expand(batch, n_agents, n_neigh, 4).to(device)\n",
    "    neigh = features.gather(dim=2, index=gather_idx)\n",
    "\n",
    "    pred_tensor = neigh[:, :n_pred]\n",
    "    prey_tensor = neigh[:, n_pred:]\n",
    "\n",
    "    if n_pred > 0:\n",
    "        mask_pred_neigh = (neigh_idx < n_pred).to(device)\n",
    "        mask_pred_neigh = mask_pred_neigh.view(1, n_agents, n_neigh, 1)\n",
    "        prey_mask = mask_pred_neigh[:, n_pred:]\n",
    "        prey_mask = prey_mask.expand(batch, -1, -1, -1).to(prey_tensor.dtype)\n",
    "\n",
    "        prey_tensor = torch.cat([prey_mask, prey_tensor], dim=-1)\n",
    "\n",
    "    return pred_tensor, prey_tensor\n",
    "\n",
    "\n",
    "def init_positions(init_pool, batch=32, area_width=2160, area_height=2160, device=\"cpu\"):\n",
    "    steps, agents, coordinates = init_pool.shape\n",
    "\n",
    "    idx = torch.randint(steps, (batch,), device=device)  # (B,)\n",
    "    positions = init_pool[idx, :agents].clone().to(device)  # (B,N,2)\n",
    "\n",
    "    positions[..., 0] *= float(area_width)\n",
    "    positions[..., 1] *= float(area_height)\n",
    "\n",
    "    center_env = torch.tensor([area_width * 0.5, area_height * 0.5],\n",
    "                              dtype=positions.dtype, device=device).view(1, 1, 2)\n",
    "\n",
    "    center_pos = positions.mean(dim=1, keepdim=True)  # (B,1,2)\n",
    "    shift = center_env - center_pos\n",
    "    positions = positions + shift\n",
    "    \n",
    "    return positions.to(torch.float32)\n",
    "\n",
    "\n",
    "def run_env_vectorized(prey_policy=None, pred_policy=None, \n",
    "                       n_prey=32, n_pred=1, \n",
    "                       step_size=1.0, batch=32,\n",
    "                       max_steps=100, seed=None, deterministic=False,\n",
    "                       prey_speed=5, pred_speed=5, \n",
    "                       area_width=2160, area_height=2160, \n",
    "                       init_pool=None):\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    n_agents = n_prey + n_pred\n",
    "    n_neigh = n_agents - 1\n",
    "\n",
    "    positions = init_positions(init_pool, batch, n_agents, area_width=area_width, area_height=area_height, device=device).to(device)\n",
    "    theta = (torch.rand((batch, n_agents), dtype=torch.float32, device=device) * 2 * torch.pi) - torch.pi\n",
    "    speed = torch.full((batch, n_agents), float(prey_speed), dtype=torch.float32, device=device)\n",
    "\n",
    "    if n_pred > 0:\n",
    "        speed[:, :n_pred] = float(pred_speed)\n",
    "        prey_traj = torch.empty((batch, max_steps, n_prey, n_neigh, 6), dtype=torch.float32, device=device)\n",
    "        pred_traj = torch.empty((batch, max_steps, n_pred, n_neigh, 5), dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        prey_traj = torch.empty((max_steps, batch, n_prey, n_neigh, 5), dtype=torch.float32, device=device)\n",
    "        pred_traj = None\n",
    "\n",
    "    idx = torch.arange(n_agents, device=device)\n",
    "    neigh_idx = idx.repeat(n_agents, 1)\n",
    "    neigh_idx = neigh_idx[~torch.eye(n_agents, dtype=torch.bool, device=device)].view(n_agents, n_agents - 1)\n",
    "\n",
    "    t = 0\n",
    "    with torch.inference_mode():\n",
    "        while t < max_steps:\n",
    "            vel = velocity_from_theta(theta, speed)\n",
    "\n",
    "            prey_pos_now = positions[:, n_pred:]\n",
    "            prey_vel_now = vel[:, n_pred:]\n",
    "            prey_dir = prey_vel_now / (torch.linalg.norm(prey_vel_now, dim=-1, keepdim=True) + 1e-12)\n",
    "            prey_log_t = torch.cat([prey_pos_now, prey_vel_now, prey_dir], dim=-1)\n",
    "\n",
    "            if n_pred > 0:\n",
    "                pred_pos_now = positions[:, :n_pred]\n",
    "                pred_vel_now = vel[:, :n_pred]\n",
    "                pred_dir = pred_vel_now / (torch.linalg.norm(pred_vel_now, dim=-1, keepdim=True) + 1e-12)\n",
    "                predator_log_t = torch.cat([pred_pos_now, pred_vel_now, pred_dir], dim=-1)\n",
    "            else:\n",
    "                predator_log_t = torch.empty((batch, 0, 6), dtype=torch.float32, device=device)\n",
    "\n",
    "            pred_states, prey_states = get_state_tensors(prey_log_t, predator_log_t,\n",
    "                                                         n_pred=n_pred,\n",
    "                                                         area_width=area_width, area_height=area_height,\n",
    "                                                         max_speed_norm=15,\n",
    "                                                         neigh_idx=neigh_idx)\n",
    "\n",
    "            if n_pred > 0:\n",
    "                pred_in = pred_states.reshape(batch * n_pred, n_neigh, 4)\n",
    "                prey_in = prey_states.reshape(batch * n_prey, n_neigh, 5)\n",
    "\n",
    "                pred_actions = pred_policy.forward(pred_in, deterministic=deterministic).view(batch, n_pred, 1)\n",
    "                prey_actions = prey_policy.forward(prey_in, deterministic=deterministic).view(batch, n_prey, 1)\n",
    "\n",
    "                pred_traj[:, t, :, :, :4] = pred_states\n",
    "                pred_traj[:, t, :, :, 4:] = pred_actions.unsqueeze(3).expand(-1, -1, n_neigh, -1)\n",
    "\n",
    "                prey_traj[:, t, :, :, :5] = prey_states\n",
    "                prey_traj[:, t, :, :, 5:] = prey_actions.unsqueeze(3).expand(-1, -1, n_neigh, -1)\n",
    "            else:\n",
    "                prey_in = prey_states.reshape(batch * n_prey, n_neigh, 4)\n",
    "                prey_actions = prey_policy.forward(prey_in, deterministic=deterministic).view(batch, n_prey, 1)\n",
    "\n",
    "                prey_traj[:, t, :, :, :4] = prey_states\n",
    "                prey_traj[:, t, :, :, 4:] = prey_actions.unsqueeze(3).expand(-1, -1, n_neigh, -1)\n",
    "\n",
    "\n",
    "            theta[:, n_pred:] = apply_turnrate(theta[:, n_pred:], prey_actions.squeeze(-1))\n",
    "            if n_pred > 0:\n",
    "                theta[:, :n_pred] = apply_turnrate(theta[:, :n_pred], pred_actions.squeeze(-1))\n",
    "\n",
    "            vel = velocity_from_theta(theta, speed)\n",
    "            positions = positions + vel * float(step_size)\n",
    "            positions, theta = enforce_walls(positions, theta, area_width, area_height)\n",
    "\n",
    "            t += 1\n",
    "\n",
    "    prey_tensor = prey_traj[:, :t]\n",
    "    pred_tensor = pred_traj[:, :t] if n_pred > 0 else None\n",
    "    return pred_tensor, prey_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5b8d950",
   "metadata": {},
   "outputs": [],
   "source": [
    "prey_policy = prey_policy.to(\"cpu\")\n",
    "pred_policy = pred_policy.to(\"cpu\") if pred_policy is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4489d24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 1.1570827960968018\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gen_pred_tensor, gen_prey_tensor = run_env_vectorized(init_pool=init_pool, batch=32,\n",
    "                                                    prey_policy=prey_policy, pred_policy=pred_policy, \n",
    "                                                    n_prey=32, n_pred=1, \n",
    "                                                    pred_speed=5, prey_speed=5,\n",
    "                                                    max_steps=100, step_size=3,\n",
    "                                                    area_width=2160, area_height=2160)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time:\", (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bd31e6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from torch.func import functional_call, vmap\n",
    "\n",
    "def init_positions(init_pool, batch=32, area_width=2160, area_height=2160,\n",
    "                   mode=\"dual\", device=\"cpu\"):\n",
    "    steps, agents, coordinates = init_pool.shape\n",
    "\n",
    "    idx = torch.randint(steps, (batch,), device=device)  # (B,)\n",
    "\n",
    "    positions = init_pool[idx, :agents].clone().to(device)  # (B,N,2)\n",
    "\n",
    "    positions[..., 0] *= float(area_width)\n",
    "    positions[..., 1] *= float(area_height)\n",
    "\n",
    "    center_env = torch.tensor([area_width * 0.5, area_height * 0.5],\n",
    "                              dtype=positions.dtype, device=device).view(1, 1, 2)\n",
    "\n",
    "    center_pos = positions.mean(dim=1, keepdim=True)  # (B,1,2)\n",
    "    shift = center_env - center_pos\n",
    "    positions = positions + shift\n",
    "\n",
    "    if mode == \"dual\":\n",
    "        positions = positions.repeat(2, 1, 1)  # (2B, N, 2)\n",
    "\n",
    "    return positions.to(torch.float32)\n",
    "\n",
    "def policy_perturbation(pred_policy, prey_policy, \n",
    "                        role=\"prey\", module=\"pairwise\", \n",
    "                        sigma=0.1, num_perturbations=32,\n",
    "                        device=\"cpu\"):\n",
    "    \n",
    "    policy = prey_policy if role == \"prey\" else pred_policy\n",
    "    base_state_dict = policy.state_dict()\n",
    "\n",
    "    prefix = \"pairwise.\" if module == \"pairwise\" else \"attention.\"\n",
    "\n",
    "    # Extract parameter keys for perturbation\n",
    "    param_keys = [k for k, v in base_state_dict.items()\n",
    "                    if k.startswith(prefix) and torch.is_tensor(v) and v.is_floating_point()]\n",
    "\n",
    "    base = OrderedDict()\n",
    "    for k, v in base_state_dict.items():\n",
    "        if torch.is_tensor(v):\n",
    "            base[k] = v.detach().to(device)\n",
    "\n",
    "    pos_list = []\n",
    "    neg_list  = []\n",
    "    epsilons = []\n",
    "\n",
    "    for _ in range(num_perturbations):\n",
    "        pos = base.copy()\n",
    "        neg = base.copy()\n",
    "\n",
    "        for k in param_keys:\n",
    "            eps = torch.randn_like(base[k])\n",
    "            pos[k] = base[k] + float(sigma) * eps\n",
    "            neg[k] = base[k] - float(sigma) * eps\n",
    "\n",
    "        pos_list.append(pos)\n",
    "        neg_list.append(neg)\n",
    "        epsilons.append(eps)\n",
    "\n",
    "    pert_list_all = pos_list + neg_list\n",
    "\n",
    "    return pert_list_all, epsilons\n",
    "\n",
    "\n",
    "def batch_policy_forward(policy, states, pert_list, deterministic=False):\n",
    "    keys = pert_list[0].keys()\n",
    "    params_batched = OrderedDict((k, torch.stack([p[k] for p in pert_list], dim=0)) for k in keys)\n",
    "\n",
    "    def vmap_function(params, x):\n",
    "        return functional_call(policy, params, (x,), kwargs={\"deterministic\": deterministic})\n",
    "\n",
    "    return vmap(vmap_function, in_dims=(0, 0), randomness=\"different\")(params_batched, states)\n",
    "\n",
    "\n",
    "def run_batch_env(prey_policy=None, pred_policy=None, \n",
    "                       n_prey=32, n_pred=1, \n",
    "                       step_size=1.0, batch=32,\n",
    "                       max_steps=100, seed=None, deterministic=False,\n",
    "                       prey_speed=5, pred_speed=5, \n",
    "                       area_width=2160, area_height=2160, \n",
    "                       init_pos=None, pert_list=None, role=\"prey\"):\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    n_agents = n_prey + n_pred\n",
    "    n_neigh = n_agents - 1\n",
    "\n",
    "    positions = init_pos.to(device)\n",
    "    theta = (torch.rand((batch, n_agents), dtype=torch.float32, device=device) * 2 * torch.pi) - torch.pi\n",
    "    speed = torch.full((batch, n_agents), float(prey_speed), dtype=torch.float32, device=device)\n",
    "\n",
    "    if n_pred > 0:\n",
    "        speed[:, :n_pred] = float(pred_speed)\n",
    "        prey_traj = torch.empty((batch, max_steps, n_prey, n_neigh, 6), dtype=torch.float32, device=device)\n",
    "        pred_traj = torch.empty((batch, max_steps, n_pred, n_neigh, 5), dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        prey_traj = torch.empty((max_steps, batch, n_prey, n_neigh, 5), dtype=torch.float32, device=device)\n",
    "        pred_traj = None\n",
    "\n",
    "    idx = torch.arange(n_agents, device=device)\n",
    "    neigh_idx = idx.repeat(n_agents, 1)\n",
    "    neigh_idx = neigh_idx[~torch.eye(n_agents, dtype=torch.bool, device=device)].view(n_agents, n_agents - 1)\n",
    "\n",
    "    t = 0\n",
    "    with torch.inference_mode():\n",
    "        while t < max_steps:\n",
    "            vel = velocity_from_theta(theta, speed)\n",
    "\n",
    "            prey_pos_now = positions[:, n_pred:]\n",
    "            prey_vel_now = vel[:, n_pred:]\n",
    "            prey_dir = prey_vel_now / (torch.linalg.norm(prey_vel_now, dim=-1, keepdim=True) + 1e-12)\n",
    "            prey_log_t = torch.cat([prey_pos_now, prey_vel_now, prey_dir], dim=-1)\n",
    "\n",
    "            if n_pred > 0:\n",
    "                pred_pos_now = positions[:, :n_pred]\n",
    "                pred_vel_now = vel[:, :n_pred]\n",
    "                pred_dir = pred_vel_now / (torch.linalg.norm(pred_vel_now, dim=-1, keepdim=True) + 1e-12)\n",
    "                predator_log_t = torch.cat([pred_pos_now, pred_vel_now, pred_dir], dim=-1)\n",
    "            else:\n",
    "                predator_log_t = torch.empty((batch, 0, 6), dtype=torch.float32, device=device)\n",
    "\n",
    "            pred_states, prey_states = get_state_tensors(prey_log_t, predator_log_t,\n",
    "                                                         n_pred=n_pred,\n",
    "                                                         area_width=area_width, area_height=area_height,\n",
    "                                                         max_speed_norm=15,\n",
    "                                                         neigh_idx=neigh_idx)\n",
    "\n",
    "            if n_pred > 0:\n",
    "                # keep env-wise shape\n",
    "                pred_in_env = pred_states.view(batch, n_pred, n_neigh, 4)  # (B, n_pred, neigh, 4)\n",
    "                prey_in_env = prey_states.view(batch, n_prey, n_neigh, 5)  # (B, n_prey, neigh, 5)\n",
    "\n",
    "                # PRED actions\n",
    "                if role in (\"pred\", \"predator\") and pert_list is not None:\n",
    "                    pred_actions = batch_policy_forward(pred_policy, pred_in_env, pert_list,\n",
    "                                                          deterministic=deterministic).view(batch, n_pred, 1)\n",
    "                else:\n",
    "                    #print(\"No perturbation on predator policy.\")\n",
    "                    pred_actions = pred_policy.forward(\n",
    "                        pred_in_env.view(batch * n_pred, n_neigh, 4),\n",
    "                        deterministic=deterministic\n",
    "                    ).view(batch, n_pred, 1)\n",
    "\n",
    "                # PREY actions\n",
    "                if role == \"prey\" and pert_list is not None:\n",
    "                    prey_actions = batch_policy_forward(prey_policy, prey_in_env, pert_list,\n",
    "                                                          deterministic=deterministic).view(batch, n_prey, 1)\n",
    "                else:\n",
    "                    #print(\"No perturbation on prey policy.\")\n",
    "                    prey_actions = prey_policy.forward(\n",
    "                        prey_in_env.view(batch * n_prey, n_neigh, 5),\n",
    "                        deterministic=deterministic\n",
    "                    ).view(batch, n_prey, 1)\n",
    "\n",
    "                pred_traj[:, t, :, :, :4] = pred_states\n",
    "                pred_traj[:, t, :, :, 4:] = pred_actions.unsqueeze(3).expand(-1, -1, n_neigh, -1)\n",
    "\n",
    "                prey_traj[:, t, :, :, :5] = prey_states\n",
    "                prey_traj[:, t, :, :, 5:] = prey_actions.unsqueeze(3).expand(-1, -1, n_neigh, -1)\n",
    "\n",
    "            else:\n",
    "                prey_in_env = prey_states.view(batch, n_prey, n_neigh, 4)\n",
    "\n",
    "                if role == \"prey\" and pert_list is not None:\n",
    "                    prey_actions = batch_policy_forward(prey_policy, prey_in_env, pert_list,\n",
    "                                                          deterministic=deterministic).view(batch, n_prey, 1)\n",
    "                else:\n",
    "                    prey_actions = prey_policy.forward(\n",
    "                        prey_in_env.view(batch * n_prey, n_neigh, 4),\n",
    "                        deterministic=deterministic\n",
    "                    ).view(batch, n_prey, 1)\n",
    "\n",
    "                prey_traj[:, t, :, :, :4] = prey_states\n",
    "                prey_traj[:, t, :, :, 4:] = prey_actions.unsqueeze(3).expand(-1, -1, n_neigh, -1)\n",
    "\n",
    "            theta[:, n_pred:] = apply_turnrate(theta[:, n_pred:], prey_actions.squeeze(-1))\n",
    "            if n_pred > 0:\n",
    "                theta[:, :n_pred] = apply_turnrate(theta[:, :n_pred], pred_actions.squeeze(-1))\n",
    "\n",
    "            vel = velocity_from_theta(theta, speed)\n",
    "            positions = positions + vel * float(step_size)\n",
    "            positions, theta = enforce_walls(positions, theta, area_width, area_height)\n",
    "\n",
    "            t += 1\n",
    "\n",
    "    prey_tensor = prey_traj[:, :t]\n",
    "    pred_tensor = pred_traj[:, :t] if n_pred > 0 else None\n",
    "    return pred_tensor, prey_tensor\n",
    "\n",
    "\n",
    "def apply_perturbations(prey_policy, pred_policy, init_pos, \n",
    "                        role, module, device,\n",
    "                        sigma, num_perturbations):\n",
    "    \n",
    "    pert_list, epsilons = policy_perturbation(pred_policy, prey_policy,\n",
    "                                            role=role, module=module,\n",
    "                                            sigma=sigma, num_perturbations=num_perturbations,\n",
    "                                            device=device)\n",
    "    \n",
    "    pred_rollouts, prey_rollouts = run_batch_env(prey_policy=prey_policy, pred_policy=pred_policy,\n",
    "                                        batch=2*num_perturbations, init_pos=init_pos,\n",
    "                                        pert_list=pert_list, role=role)\n",
    "    \n",
    "    return pred_rollouts, prey_rollouts, epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5b2a61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_pool_path = rf\"..\\data\\1. Data Processing\\processed\\init_pool\\init_pool.pt\"\n",
    "init_pool = torch.load(init_pool_path)\n",
    "\n",
    "init_pos = init_positions(init_pool, batch=32, mode=\"dual\")\n",
    "\n",
    "pred_rollouts, prey_rollouts, epsilons = apply_perturbations(prey_policy, pred_policy, init_pos,\n",
    "                               role=\"prey\", module=\"pairwise\", device=\"cpu\",\n",
    "                               sigma=0.1, num_perturbations=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36424c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_es(pred_policy, prey_policy, \n",
    "                role, module, \n",
    "                discriminator, lr, \n",
    "                sigma, num_perturbations, \n",
    "                device=\"cuda\", init_pos=None):\n",
    "    \n",
    "    if role == \"prey\":\n",
    "        network = prey_policy.pairwise if module == 'pairwise' else prey_policy.attention\n",
    "    else:\n",
    "        network = pred_policy.pairwise if module == 'pairwise' else pred_policy.attention\n",
    "\n",
    "    theta = nn.utils.parameters_to_vector(network.parameters())\n",
    "\n",
    "    pred_rollouts, prey_rollouts, epsilons = apply_perturbations(prey_policy, pred_policy, init_pos,\n",
    "                                role=role, module=module, device=device,\n",
    "                                sigma=sigma, num_perturbations=num_perturbations)\n",
    "    \n",
    "    if role == \"prey\":\n",
    "        reward = discriminator_reward(discriminator, prey_rollouts, mode=\"top\")\n",
    "    else:\n",
    "        reward = discriminator_reward(discriminator, pred_rollouts, mode=\"top\")\n",
    "\n",
    "    reward_pos = reward[:num_perturbations]\n",
    "    reward_neg = reward[num_perturbations:]\n",
    "\n",
    "    diffs = (reward_pos - reward_neg).detach()\n",
    "    ranks = torch.argsort(torch.argsort(diffs)).float()\n",
    "    ranks_norm = (ranks - ranks.mean()) / (ranks.std() + 1e-8)\n",
    "\n",
    "    theta_est, grad_metrics = gradient_estimate(theta, ranks_norm, epsilons, sigma, lr, num_perturbations)\n",
    "\n",
    "    # if std is too small, do not update (Random Walk)\n",
    "    if diffs.std(unbiased=False) < 1e-6:\n",
    "        theta_est = theta\n",
    "\n",
    "    nn.utils.vector_to_parameters(theta_est, network.parameters())\n",
    "    \n",
    "    return {\"diff_min\": round(diffs.min().item(), 6),\n",
    "            \"diff_max\": round(diffs.max().item(), 6),\n",
    "            \"diff_mean\": round(diffs.mean().item(), 6),\n",
    "            \"diff_std\": round(diffs.std(unbiased=False).item(), 6),\n",
    "            \"delta_norm\": round((theta_est - theta).norm().item(), 6),\n",
    "            \"clip_ratio\": round(grad_metrics[\"clip_ratio\"], 6),\n",
    "            \"delta_raw_norm\": round(grad_metrics[\"delta_raw_norm\"], 6),\n",
    "            \"max_delta_norm\": round(grad_metrics[\"max_delta_norm\"], 6)\n",
    "        }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAIL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
