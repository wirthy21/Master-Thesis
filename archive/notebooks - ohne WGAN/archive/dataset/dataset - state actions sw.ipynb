{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "407fa156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from utils.dataset_utils import get_swarm_data, get_quality_score, get_full_tracks, get_tensor, group_and_save_tensors, get_state_actions, group_and_save_state_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f0b68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# References: \n",
    "# https://learnopencv.com/real-time-deep-sort-with-torchvision-detectors/#Real-Time-Deep-SORT-Setup\n",
    "# https://pypi.org/project/deep-sort-realtime/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b988225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_video_folder = r'C:\\Users\\janni\\OneDrive\\Dokumente\\Privat\\Bildung\\M. Sc. Social and Economic Data Science\\4. Semester\\Master Thesis\\Code\\data\\raw\\videos'\n",
    "yolo_path = r'C:\\Users\\janni\\OneDrive\\Dokumente\\Privat\\Bildung\\M. Sc. Social and Economic Data Science\\4. Semester\\Master Thesis\\Code\\models\\costumized_yolo\\costumized_yolo\\costumized_yolo.pt'\n",
    "output_folder = r'C:\\Users\\janni\\OneDrive\\Dokumente\\Privat\\Bildung\\M. Sc. Social and Economic Data Science\\4. Semester\\Master Thesis\\Code\\data\\processed\\state_actions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "188e5765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "video = \"video_8min\" #60 min\n",
    "clip_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d814b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 30.0\n",
      "Total frames: 14471\n",
      "Duration (s): 482.37\n",
      "Total trajectories: 14462\n",
      "Prey Count: 32\n",
      "Predator Count: 1\n"
     ]
    }
   ],
   "source": [
    "video_path = raw_video_folder + \"\\\\\" + video + \".mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = total_frames / fps\n",
    "total_traj = total_frames - clip_size + 1\n",
    "\n",
    "print(f\"FPS: {fps}\")\n",
    "print(f\"Total frames: {total_frames}\")\n",
    "print(f\"Duration (s): {duration:.2f}\")\n",
    "print(f\"Total trajectories: {total_traj}\")\n",
    "print(\"Prey Count: 32\")\n",
    "print(\"Predator Count: 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8414dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clip 0] Startframe: 0, Endframe: 9\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 35 Preys, 42.3ms\n",
      "Speed: 5.7ms preprocess, 42.3ms inference, 3.8ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 21.5ms\n",
      "Speed: 4.8ms preprocess, 21.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 31 Preys, 13.7ms\n",
      "Speed: 5.8ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 31 Preys, 12.6ms\n",
      "Speed: 5.0ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 13.0ms\n",
      "Speed: 4.7ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 12.5ms\n",
      "Speed: 4.9ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 15.1ms\n",
      "Speed: 6.5ms preprocess, 15.1ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 15.1ms\n",
      "Speed: 6.1ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 13.3ms\n",
      "Speed: 4.8ms preprocess, 13.3ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 15.4ms\n",
      "Speed: 6.6ms preprocess, 15.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 7.542857142857143\n",
      "Number of full tracks: 0\n",
      "Mean confidence: 0.7202072931270973\n",
      "No full tracks found.\n",
      "[Clip 1] Startframe: 1, Endframe: 10\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 12.3ms\n",
      "Speed: 6.0ms preprocess, 12.3ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 31 Preys, 12.5ms\n",
      "Speed: 5.3ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 31 Preys, 15.7ms\n",
      "Speed: 5.0ms preprocess, 15.7ms inference, 3.4ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 15.0ms\n",
      "Speed: 5.7ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 14.1ms\n",
      "Speed: 5.3ms preprocess, 14.1ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 12.8ms\n",
      "Speed: 6.1ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 14.7ms\n",
      "Speed: 6.8ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 11.4ms\n",
      "Speed: 4.5ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 12.1ms\n",
      "Speed: 5.3ms preprocess, 12.1ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 19.6ms\n",
      "Speed: 8.8ms preprocess, 19.6ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 8.0\n",
      "Number of full tracks: 23\n",
      "Mean confidence: 0.7173671118522945\n",
      "[Clip 2] Startframe: 2, Endframe: 11\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 31 Preys, 11.8ms\n",
      "Speed: 4.8ms preprocess, 11.8ms inference, 4.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 31 Preys, 16.2ms\n",
      "Speed: 5.0ms preprocess, 16.2ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 11.5ms\n",
      "Speed: 6.9ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 12.6ms\n",
      "Speed: 4.6ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 12.5ms\n",
      "Speed: 5.1ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 13.8ms\n",
      "Speed: 5.3ms preprocess, 13.8ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 14.6ms\n",
      "Speed: 5.3ms preprocess, 14.6ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 12.6ms\n",
      "Speed: 4.7ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 15.3ms\n",
      "Speed: 4.9ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 35 Preys, 11.3ms\n",
      "Speed: 7.8ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 8.152173913043478\n",
      "Number of full tracks: 25\n",
      "Mean confidence: 0.7190902204000988\n",
      "[Clip 3] Startframe: 3, Endframe: 12\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 31 Preys, 11.0ms\n",
      "Speed: 4.8ms preprocess, 11.0ms inference, 4.4ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 12.7ms\n",
      "Speed: 4.8ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 13.4ms\n",
      "Speed: 6.9ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 13.9ms\n",
      "Speed: 5.3ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 13.6ms\n",
      "Speed: 4.8ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 14.1ms\n",
      "Speed: 5.3ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 12.3ms\n",
      "Speed: 4.5ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 13.9ms\n",
      "Speed: 6.1ms preprocess, 13.9ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 35 Preys, 13.4ms\n",
      "Speed: 5.0ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 12.5ms\n",
      "Speed: 4.8ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 7.7\n",
      "Number of full tracks: 20\n",
      "Mean confidence: 0.7218551287878903\n",
      "[Clip 4] Startframe: 4, Endframe: 13\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 11.4ms\n",
      "Speed: 5.2ms preprocess, 11.4ms inference, 3.5ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 11.3ms\n",
      "Speed: 4.6ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 21.1ms\n",
      "Speed: 6.8ms preprocess, 21.1ms inference, 3.5ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 11.3ms\n",
      "Speed: 4.5ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 10.7ms\n",
      "Speed: 5.6ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 15.4ms\n",
      "Speed: 5.3ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 14.7ms\n",
      "Speed: 5.3ms preprocess, 14.7ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 35 Preys, 12.3ms\n",
      "Speed: 5.1ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 12.5ms\n",
      "Speed: 5.7ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 31 Preys, 11.3ms\n",
      "Speed: 4.9ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 7.296296296296297\n",
      "Number of full tracks: 17\n",
      "Mean confidence: 0.7250497530900896\n",
      "[Clip 5] Startframe: 5, Endframe: 14\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 11.2ms\n",
      "Speed: 5.1ms preprocess, 11.2ms inference, 4.4ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 12.4ms\n",
      "Speed: 4.6ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 14.4ms\n",
      "Speed: 6.5ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 14.2ms\n",
      "Speed: 5.7ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 11.0ms\n",
      "Speed: 5.6ms preprocess, 11.0ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 12.6ms\n",
      "Speed: 4.8ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 35 Preys, 11.5ms\n",
      "Speed: 5.3ms preprocess, 11.5ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 12.1ms\n",
      "Speed: 4.9ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 31 Preys, 14.7ms\n",
      "Speed: 5.5ms preprocess, 14.7ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 17.3ms\n",
      "Speed: 4.8ms preprocess, 17.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 7.471698113207547\n",
      "Number of full tracks: 19\n",
      "Mean confidence: 0.7248657171418067\n"
     ]
    }
   ],
   "source": [
    "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model   = YOLO(yolo_path)\n",
    "tracker = DeepSort(max_age=5)\n",
    "\n",
    "tensor_data = []\n",
    "video_idx   = 0\n",
    "\n",
    "for start_frame in range(total_traj):\n",
    "    end_frame = start_frame + clip_size - 1\n",
    "    print(f\"[Clip {video_idx}] Startframe: {start_frame}, Endframe: {end_frame}\")\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    frames = []\n",
    "    for _ in range(clip_size):\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    if len(frames) < clip_size:\n",
    "        break\n",
    "\n",
    "    dfs = []\n",
    "    for offset, frm in enumerate(frames):\n",
    "        frame_idx = start_frame + offset\n",
    "        df = get_swarm_data(frm, model, tracker, frame_idx)\n",
    "        dfs.append(df)\n",
    "\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    mean_track_visibility, num_full_tracks, mean_confidence = get_quality_score(combined_df, n=clip_size)\n",
    "    video_idx += 1\n",
    "\n",
    "    full_tracks_df = get_full_tracks(combined_df, n=clip_size)\n",
    "    if not full_tracks_df.empty:\n",
    "        tensor_data.append(get_state_actions(full_tracks_df))\n",
    "\n",
    "cap.release()\n",
    "\n",
    "group_and_save_state_actions(video, tensor_data, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
