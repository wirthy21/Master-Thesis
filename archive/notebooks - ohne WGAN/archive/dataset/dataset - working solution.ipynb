{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "407fa156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import math\n",
    "from ultralytics import YOLO\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f0b68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# References: \n",
    "# https://learnopencv.com/real-time-deep-sort-with-torchvision-detectors/#Real-Time-Deep-SORT-Setup\n",
    "# https://pypi.org/project/deep-sort-realtime/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b988225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_video_folder = r'C:\\Users\\janni\\OneDrive\\Dokumente\\Privat\\Bildung\\M. Sc. Social and Economic Data Science\\4. Semester\\Master Thesis\\Code\\data\\raw\\videos'\n",
    "yolo_path      = r'C:\\Users\\janni\\OneDrive\\Dokumente\\Privat\\Bildung\\M. Sc. Social and Economic Data Science\\4. Semester\\Master Thesis\\Code\\models\\costumized_yolo\\costumized_yolo\\costumized_yolo.pt'\n",
    "output_folder    = r'C:\\Users\\janni\\OneDrive\\Dokumente\\Privat\\Bildung\\M. Sc. Social and Economic Data Science\\4. Semester\\Master Thesis\\Code\\data\\processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7ab489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_swarm_data(frame, model, tracker, frame_idx):\n",
    "    records = []\n",
    "\n",
    "    # YOLO inference\n",
    "    results = model(frame)[0]\n",
    "    bboxes, confidences, class_ids = [], [], []\n",
    "\n",
    "    for box, score, cls in zip(results.boxes.xyxy.cpu().numpy(), results.boxes.conf.cpu().numpy(), results.boxes.cls.cpu().numpy()):\n",
    "        label = model.names[int(cls)]\n",
    "        \n",
    "        if label not in (\"Prey\", \"Predator Head\"):\n",
    "            continue\n",
    "        \n",
    "        x1, y1, x2, y2 = box\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        bboxes.append([x1, y1, w, h])\n",
    "        confidences.append(float(score))\n",
    "        class_ids.append(label)\n",
    "\n",
    "    detections = list(zip(bboxes, confidences, class_ids))\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "    for t in tracks:\n",
    "        if not t.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        tid = t.track_id\n",
    "        cx, cy = t.mean[0], t.mean[1]\n",
    "        vx, vy = float(t.mean[4]), float(t.mean[5])\n",
    "        speed = np.hypot(vx, vy)\n",
    "        angle = np.degrees(np.arctan2(vy, vx))\n",
    "        label = t.det_class\n",
    "        conf = t.det_conf\n",
    "\n",
    "        records.append({\n",
    "            \"frame\":    int(frame_idx),\n",
    "            \"track_id\": int(tid),\n",
    "            \"label\":    str(label),\n",
    "            \"conf\":     conf,\n",
    "            \"x\":        float(cx),\n",
    "            \"y\":        float(cy),\n",
    "            \"vx\":       float(vx),\n",
    "            \"vy\":       float(vy),\n",
    "            \"speed\":    float(speed),\n",
    "            \"angle\":    float(angle),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4526534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quality_score(df, n=10):\n",
    "    track_counts = df.groupby(\"track_id\")[\"frame\"].nunique()\n",
    "    mean_track_visibility = track_counts.mean()\n",
    "\n",
    "    num_full_tracks = (track_counts == n).sum()\n",
    "\n",
    "    mean_confidence = df[\"conf\"].mean()\n",
    "\n",
    "    print(f\"Mean track visibility: {mean_track_visibility}\")\n",
    "    print(f\"Number of full tracks: {num_full_tracks}\")\n",
    "    print(f\"Mean confidence: {mean_confidence}\")\n",
    "\n",
    "    return mean_track_visibility, num_full_tracks, mean_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4efe735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_tracks(df, min_frames):\n",
    "    counts = df.groupby(\"track_id\")[\"frame\"].nunique()\n",
    "    good_ids = counts[counts == min_frames].index\n",
    "    return df[df[\"track_id\"].isin(good_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12475b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor(df):\n",
    "    # Einzigartige Frame-Indices und Track-IDs sammeln\n",
    "    frame_indices = sorted(df[\"frame\"].unique())\n",
    "    track_ids = sorted(df[\"track_id\"].unique())\n",
    "    T = len(frame_indices)\n",
    "    N = len(track_ids)\n",
    "\n",
    "    # Mapping von track_id -> Index in unseren Arrays\n",
    "    track_id_to_index = {track_id: idx for idx, track_id in enumerate(track_ids)}\n",
    "\n",
    "    # Ergebnis-Tensor: [T, N, N-1, 4] für [dx, dy, vx_i, vy_i]\n",
    "    relative_motion_tensor = torch.zeros((T, N, N-1, 4), dtype=torch.float32)\n",
    "\n",
    "    for t_idx, frame_id in enumerate(frame_indices):\n",
    "        frame_df = df[df[\"frame\"] == frame_id]\n",
    "\n",
    "        # Positionen (N×2) und Winkel (N) in Arrays bringen\n",
    "        positions = np.stack([frame_df.loc[frame_df.track_id == tid, [\"x\", \"y\"]].values[0] for tid in track_ids])\n",
    "        velocities = np.stack([frame_df.loc[frame_df.track_id == tid, [\"vx\", \"vy\"]].values[0] for tid in track_ids])\n",
    "\n",
    "        # Winkel des Fokal-Agents in Radiant\n",
    "        angles_rad = np.deg2rad(frame_df.set_index(\"track_id\")[\"angle\"].reindex(track_ids).values)\n",
    "\n",
    "        for i in range(N):\n",
    "            # Index aller anderen Agents\n",
    "            neighbor_indices = [j for j in range(N) if j != i]\n",
    "\n",
    "            # Relative Position = neighbor_pos - focal_pos\n",
    "            delta_positions = positions[neighbor_indices] - positions[i]  # shape (N-1,2)\n",
    "\n",
    "            # Roh-Geschwindigkeitsvektoren der Nachbarn\n",
    "            neighbor_velocities = velocities[neighbor_indices]             # shape (N-1,2)\n",
    "\n",
    "            # Rotationsmatrix, um in das Koordinatensystem des Fokal-Agents zu wechseln\n",
    "            cos_theta = np.cos(-angles_rad[i])\n",
    "            sin_theta = np.sin(-angles_rad[i])\n",
    "            \n",
    "            rotation_matrix = np.array([[cos_theta, -sin_theta],\n",
    "                                        [sin_theta,  cos_theta]])\n",
    "\n",
    "            # Nachbar-Geschwindigkeit im Fokal-Koordinatensystem\n",
    "            rotated_neighbor_velocities = neighbor_velocities @ rotation_matrix.T  # (N-1,2)\n",
    "\n",
    "            # 4-dim Feature: [dx, dy, vx_i, vy_i]\n",
    "            edge_features = np.hstack([delta_positions, rotated_neighbor_velocities])  # (N-1,4)\n",
    "\n",
    "            # In den Tensor speichern\n",
    "            relative_motion_tensor[t_idx, i] = torch.from_numpy(edge_features.astype(np.float32))\n",
    "\n",
    "    return relative_motion_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "869cf833",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipDataset(Dataset):\n",
    "    def __init__(self, clips_list):\n",
    "        self.clips = clips_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.clips)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.clips[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d814b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 30.0\n",
      "Total frames: 153\n",
      "Duration (s): 5.10\n",
      "Prey Count: 32\n",
      "Predator Count: 1\n"
     ]
    }
   ],
   "source": [
    "video = \"video_5s\" #58 min\n",
    "video_path = raw_video_folder + \"\\\\\" + video + \".mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = total_frames / fps\n",
    "\n",
    "print(f\"FPS: {fps}\")\n",
    "print(f\"Total frames: {total_frames}\")\n",
    "print(f\"Duration (s): {duration:.2f}\")\n",
    "print(\"Prey Count: 32\")\n",
    "print(\"Predator Count: 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1dc8ab1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 827.7ms\n",
      "Speed: 21.1ms preprocess, 827.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 662.3ms\n",
      "Speed: 21.5ms preprocess, 662.3ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 678.4ms\n",
      "Speed: 15.0ms preprocess, 678.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 35 Preys, 643.6ms\n",
      "Speed: 17.0ms preprocess, 643.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 35 Preys, 615.4ms\n",
      "Speed: 16.4ms preprocess, 615.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 609.0ms\n",
      "Speed: 15.3ms preprocess, 609.0ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 619.8ms\n",
      "Speed: 17.0ms preprocess, 619.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 605.2ms\n",
      "Speed: 12.7ms preprocess, 605.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 670.8ms\n",
      "Speed: 19.2ms preprocess, 670.8ms inference, 4.5ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 644.4ms\n",
      "Speed: 14.9ms preprocess, 644.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 7.526315789473684\n",
      "Number of full tracks: 0\n",
      "Mean confidence: 0.7258825054518262\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 905.3ms\n",
      "Speed: 10.3ms preprocess, 905.3ms inference, 4.3ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 1447.4ms\n",
      "Speed: 16.4ms preprocess, 1447.4ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 1353.6ms\n",
      "Speed: 19.6ms preprocess, 1353.6ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 30 Preys, 1149.5ms\n",
      "Speed: 33.2ms preprocess, 1149.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 1814.5ms\n",
      "Speed: 16.1ms preprocess, 1814.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 711.7ms\n",
      "Speed: 25.3ms preprocess, 711.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 782.1ms\n",
      "Speed: 17.4ms preprocess, 782.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 1656.7ms\n",
      "Speed: 14.9ms preprocess, 1656.7ms inference, 6.8ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 1748.2ms\n",
      "Speed: 17.4ms preprocess, 1748.2ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 1417.7ms\n",
      "Speed: 13.1ms preprocess, 1417.7ms inference, 4.3ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 8.463414634146341\n",
      "Number of full tracks: 29\n",
      "Mean confidence: 0.7156119082440338\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 1133.6ms\n",
      "Speed: 11.9ms preprocess, 1133.6ms inference, 4.6ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 620.9ms\n",
      "Speed: 20.3ms preprocess, 620.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 643.4ms\n",
      "Speed: 12.5ms preprocess, 643.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 30 Preys, 612.6ms\n",
      "Speed: 16.2ms preprocess, 612.6ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 29 Preys, 768.2ms\n",
      "Speed: 18.4ms preprocess, 768.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 29 Preys, 677.1ms\n",
      "Speed: 15.1ms preprocess, 677.1ms inference, 3.3ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 30 Preys, 727.7ms\n",
      "Speed: 16.5ms preprocess, 727.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 30 Preys, 642.0ms\n",
      "Speed: 17.5ms preprocess, 642.0ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 30 Preys, 613.6ms\n",
      "Speed: 16.8ms preprocess, 613.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 30 Preys, 654.9ms\n",
      "Speed: 19.6ms preprocess, 654.9ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 8.846153846153847\n",
      "Number of full tracks: 29\n",
      "Mean confidence: 0.707936206718733\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 30 Preys, 1046.0ms\n",
      "Speed: 11.5ms preprocess, 1046.0ms inference, 4.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 29 Preys, 661.6ms\n",
      "Speed: 16.5ms preprocess, 661.6ms inference, 4.5ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 30 Preys, 651.0ms\n",
      "Speed: 17.0ms preprocess, 651.0ms inference, 3.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 689.0ms\n",
      "Speed: 16.0ms preprocess, 689.0ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 662.8ms\n",
      "Speed: 16.7ms preprocess, 662.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 658.4ms\n",
      "Speed: 16.5ms preprocess, 658.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 749.0ms\n",
      "Speed: 13.4ms preprocess, 749.0ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 606.6ms\n",
      "Speed: 15.9ms preprocess, 606.6ms inference, 3.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 1215.2ms\n",
      "Speed: 17.6ms preprocess, 1215.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 1218.0ms\n",
      "Speed: 30.3ms preprocess, 1218.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 8.64102564102564\n",
      "Number of full tracks: 30\n",
      "Mean confidence: 0.7156023033370542\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 33 Preys, 1230.1ms\n",
      "Speed: 12.2ms preprocess, 1230.1ms inference, 5.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 30 Preys, 775.6ms\n",
      "Speed: 16.4ms preprocess, 775.6ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator Head, 29 Preys, 691.0ms\n",
      "Speed: 15.6ms preprocess, 691.0ms inference, 6.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 32 Preys, 706.3ms\n",
      "Speed: 16.7ms preprocess, 706.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 31 Preys, 675.5ms\n",
      "Speed: 17.6ms preprocess, 675.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 30 Preys, 825.9ms\n",
      "Speed: 16.0ms preprocess, 825.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 30 Preys, 910.3ms\n",
      "Speed: 23.6ms preprocess, 910.3ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 31 Preys, 720.2ms\n",
      "Speed: 18.1ms preprocess, 720.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 34 Preys, 601.3ms\n",
      "Speed: 10.3ms preprocess, 601.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 31 Preys, 626.7ms\n",
      "Speed: 15.2ms preprocess, 626.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 8.414634146341463\n",
      "Number of full tracks: 29\n",
      "Mean confidence: 0.7049353953475267\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 30 Preys, 1869.8ms\n",
      "Speed: 22.2ms preprocess, 1869.8ms inference, 4.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 29 Preys, 703.2ms\n",
      "Speed: 18.7ms preprocess, 703.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 29 Preys, 2005.9ms\n",
      "Speed: 14.0ms preprocess, 2005.9ms inference, 6.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 31 Preys, 608.5ms\n",
      "Speed: 16.7ms preprocess, 608.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 30 Preys, 609.2ms\n",
      "Speed: 16.3ms preprocess, 609.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 30 Preys, 608.5ms\n",
      "Speed: 14.6ms preprocess, 608.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 30 Preys, 610.1ms\n",
      "Speed: 16.5ms preprocess, 610.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 29 Preys, 598.1ms\n",
      "Speed: 11.3ms preprocess, 598.1ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 29 Preys, 639.9ms\n",
      "Speed: 15.5ms preprocess, 639.9ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 29 Preys, 1382.8ms\n",
      "Speed: 17.0ms preprocess, 1382.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 8.538461538461538\n",
      "Number of full tracks: 28\n",
      "Mean confidence: 0.7258100075523058\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 873.5ms\n",
      "Speed: 16.4ms preprocess, 873.5ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 29 Preys, 695.9ms\n",
      "Speed: 16.0ms preprocess, 695.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 2 Predator Heads, 31 Preys, 652.9ms\n",
      "Speed: 18.5ms preprocess, 652.9ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 2 Predator Heads, 33 Preys, 701.9ms\n",
      "Speed: 17.3ms preprocess, 701.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 2 Predator Heads, 32 Preys, 700.2ms\n",
      "Speed: 14.5ms preprocess, 700.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 2046.2ms\n",
      "Speed: 16.6ms preprocess, 2046.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 620.5ms\n",
      "Speed: 14.7ms preprocess, 620.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 32 Preys, 713.6ms\n",
      "Speed: 19.2ms preprocess, 713.6ms inference, 3.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 32 Preys, 1224.0ms\n",
      "Speed: 14.5ms preprocess, 1224.0ms inference, 3.4ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 32 Preys, 758.2ms\n",
      "Speed: 14.5ms preprocess, 758.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 8.625\n",
      "Number of full tracks: 29\n",
      "Mean confidence: 0.6932460356143213\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 32 Preys, 1161.1ms\n",
      "Speed: 12.0ms preprocess, 1161.1ms inference, 12.8ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 29 Preys, 604.8ms\n",
      "Speed: 10.9ms preprocess, 604.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 28 Preys, 753.1ms\n",
      "Speed: 14.0ms preprocess, 753.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 2 Predators, 2 Predator Heads, 28 Preys, 584.7ms\n",
      "Speed: 14.7ms preprocess, 584.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 28 Preys, 586.9ms\n",
      "Speed: 10.5ms preprocess, 586.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 29 Preys, 586.9ms\n",
      "Speed: 11.8ms preprocess, 586.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 29 Preys, 637.3ms\n",
      "Speed: 14.9ms preprocess, 637.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 30 Preys, 596.3ms\n",
      "Speed: 19.9ms preprocess, 596.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 29 Preys, 597.0ms\n",
      "Speed: 13.6ms preprocess, 597.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 1292.7ms\n",
      "Speed: 16.9ms preprocess, 1292.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 8.55\n",
      "Number of full tracks: 30\n",
      "Mean confidence: 0.6903698353577923\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 29 Preys, 1059.3ms\n",
      "Speed: 11.9ms preprocess, 1059.3ms inference, 4.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 28 Preys, 628.2ms\n",
      "Speed: 12.3ms preprocess, 628.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 28 Preys, 624.6ms\n",
      "Speed: 15.1ms preprocess, 624.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 29 Preys, 624.1ms\n",
      "Speed: 16.0ms preprocess, 624.1ms inference, 3.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 610.1ms\n",
      "Speed: 15.7ms preprocess, 610.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 616.0ms\n",
      "Speed: 16.2ms preprocess, 616.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 32 Preys, 610.7ms\n",
      "Speed: 16.2ms preprocess, 610.7ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 616.6ms\n",
      "Speed: 15.5ms preprocess, 616.6ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 609.6ms\n",
      "Speed: 11.0ms preprocess, 609.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 32 Preys, 733.1ms\n",
      "Speed: 12.2ms preprocess, 733.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 8.710526315789474\n",
      "Number of full tracks: 29\n",
      "Mean confidence: 0.690601037791023\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 30 Preys, 1048.6ms\n",
      "Speed: 10.1ms preprocess, 1048.6ms inference, 5.4ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 33 Preys, 626.2ms\n",
      "Speed: 16.7ms preprocess, 626.2ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 33 Preys, 619.9ms\n",
      "Speed: 11.5ms preprocess, 619.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 34 Preys, 621.8ms\n",
      "Speed: 12.1ms preprocess, 621.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 34 Preys, 625.8ms\n",
      "Speed: 16.0ms preprocess, 625.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 35 Preys, 623.5ms\n",
      "Speed: 14.7ms preprocess, 623.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 34 Preys, 613.1ms\n",
      "Speed: 16.8ms preprocess, 613.1ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 30 Preys, 615.3ms\n",
      "Speed: 13.7ms preprocess, 615.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 617.2ms\n",
      "Speed: 14.8ms preprocess, 617.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 32 Preys, 606.5ms\n",
      "Speed: 13.7ms preprocess, 606.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 8.477272727272727\n",
      "Number of full tracks: 31\n",
      "Mean confidence: 0.645009060639032\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 32 Preys, 1052.1ms\n",
      "Speed: 10.8ms preprocess, 1052.1ms inference, 5.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 704.9ms\n",
      "Speed: 16.4ms preprocess, 704.9ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 685.3ms\n",
      "Speed: 15.1ms preprocess, 685.3ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 30 Preys, 1212.8ms\n",
      "Speed: 21.1ms preprocess, 1212.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 32 Preys, 665.1ms\n",
      "Speed: 18.3ms preprocess, 665.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 32 Preys, 627.7ms\n",
      "Speed: 18.3ms preprocess, 627.7ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 624.7ms\n",
      "Speed: 19.2ms preprocess, 624.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 32 Preys, 609.2ms\n",
      "Speed: 13.9ms preprocess, 609.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 32 Preys, 610.9ms\n",
      "Speed: 17.9ms preprocess, 610.9ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 34 Preys, 610.3ms\n",
      "Speed: 17.5ms preprocess, 610.3ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 7.913043478260869\n",
      "Number of full tracks: 30\n",
      "Mean confidence: 0.6709252403389593\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 33 Preys, 826.9ms\n",
      "Speed: 11.9ms preprocess, 826.9ms inference, 5.4ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 33 Preys, 597.7ms\n",
      "Speed: 16.1ms preprocess, 597.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 32 Preys, 602.9ms\n",
      "Speed: 16.4ms preprocess, 602.9ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 614.0ms\n",
      "Speed: 16.3ms preprocess, 614.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 34 Preys, 592.9ms\n",
      "Speed: 13.1ms preprocess, 592.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 32 Preys, 594.9ms\n",
      "Speed: 15.8ms preprocess, 594.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 30 Preys, 593.7ms\n",
      "Speed: 14.7ms preprocess, 593.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 586.5ms\n",
      "Speed: 12.1ms preprocess, 586.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 765.2ms\n",
      "Speed: 83.4ms preprocess, 765.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 30 Preys, 606.2ms\n",
      "Speed: 12.6ms preprocess, 606.2ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 8.44186046511628\n",
      "Number of full tracks: 30\n",
      "Mean confidence: 0.6657894331516709\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 30 Preys, 1037.5ms\n",
      "Speed: 12.5ms preprocess, 1037.5ms inference, 4.6ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 30 Preys, 600.1ms\n",
      "Speed: 14.8ms preprocess, 600.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 29 Preys, 598.8ms\n",
      "Speed: 15.5ms preprocess, 598.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 27 Preys, 598.1ms\n",
      "Speed: 16.5ms preprocess, 598.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 27 Preys, 579.2ms\n",
      "Speed: 15.8ms preprocess, 579.2ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 28 Preys, 589.1ms\n",
      "Speed: 10.9ms preprocess, 589.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 585.8ms\n",
      "Speed: 12.2ms preprocess, 585.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 29 Preys, 591.5ms\n",
      "Speed: 15.0ms preprocess, 591.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 593.0ms\n",
      "Speed: 11.9ms preprocess, 593.0ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 617.2ms\n",
      "Speed: 12.2ms preprocess, 617.2ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 8.071428571428571\n",
      "Number of full tracks: 29\n",
      "Mean confidence: 0.6753514468669891\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 1109.3ms\n",
      "Speed: 13.1ms preprocess, 1109.3ms inference, 6.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 31 Preys, 637.2ms\n",
      "Speed: 12.3ms preprocess, 637.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 33 Preys, 641.2ms\n",
      "Speed: 14.1ms preprocess, 641.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 33 Preys, 655.1ms\n",
      "Speed: 16.6ms preprocess, 655.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 30 Preys, 627.7ms\n",
      "Speed: 17.7ms preprocess, 627.7ms inference, 4.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 27 Preys, 639.8ms\n",
      "Speed: 16.1ms preprocess, 639.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 27 Preys, 631.0ms\n",
      "Speed: 16.4ms preprocess, 631.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 30 Preys, 622.9ms\n",
      "Speed: 17.2ms preprocess, 622.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 30 Preys, 637.8ms\n",
      "Speed: 16.1ms preprocess, 637.8ms inference, 3.5ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 29 Preys, 632.6ms\n",
      "Speed: 13.2ms preprocess, 632.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 8.186046511627907\n",
      "Number of full tracks: 29\n",
      "Mean confidence: 0.6594379697725227\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 25 Preys, 1001.7ms\n",
      "Speed: 11.6ms preprocess, 1001.7ms inference, 5.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 27 Preys, 625.3ms\n",
      "Speed: 14.0ms preprocess, 625.3ms inference, 3.4ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 27 Preys, 635.9ms\n",
      "Speed: 15.9ms preprocess, 635.9ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 26 Preys, 622.7ms\n",
      "Speed: 14.3ms preprocess, 622.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 25 Preys, 618.1ms\n",
      "Speed: 15.8ms preprocess, 618.1ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 27 Preys, 620.7ms\n",
      "Speed: 16.4ms preprocess, 620.7ms inference, 3.8ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 26 Preys, 619.5ms\n",
      "Speed: 14.7ms preprocess, 619.5ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 26 Preys, 622.5ms\n",
      "Speed: 18.1ms preprocess, 622.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 26 Preys, 606.7ms\n",
      "Speed: 16.7ms preprocess, 606.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 27 Preys, 611.9ms\n",
      "Speed: 14.3ms preprocess, 611.9ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 8.210526315789474\n",
      "Number of full tracks: 25\n",
      "Mean confidence: 0.6611377136375671\n",
      "\n",
      "0: 736x736 1 Predator, 1 Predator Head, 30 Preys, 608.6ms\n",
      "Speed: 13.9ms preprocess, 608.6ms inference, 4.2ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 29 Preys, 614.1ms\n",
      "Speed: 10.9ms preprocess, 614.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 736)\n",
      "\n",
      "0: 736x736 1 Predator, 2 Predator Heads, 27 Preys, 730.7ms\n",
      "Speed: 11.2ms preprocess, 730.7ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 736)\n",
      "Mean track visibility: 2.78125\n",
      "Number of full tracks: 0\n",
      "Mean confidence: 0.6181614864617586\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = YOLO(yolo_path)\n",
    "tracker = DeepSort(max_age=5)\n",
    "\n",
    "num_agents = 33 #32 Prey + 1 Predator\n",
    "threshold = math.floor(num_agents * 0.9)\n",
    "video_size = 10\n",
    "\n",
    "video_idx = 0\n",
    "frame_idx = 0\n",
    "tensor_data = []\n",
    "\n",
    "while True:\n",
    "    frames = []\n",
    "    for i in range(video_size):\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "\n",
    "    if not frames:\n",
    "        break\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for frame in frames:\n",
    "        df = get_swarm_data(frame, model, tracker, frame_idx)\n",
    "        results.append(df)\n",
    "        frame_idx += 1\n",
    "\n",
    "    combined_df = pd.concat(results, ignore_index=True)\n",
    "    mean_track_visibility, num_full_tracks, mean_confidence = get_quality_score(combined_df, n=video_size)\n",
    "    video_idx += 1\n",
    "\n",
    "    \n",
    "    if num_full_tracks >= threshold:\n",
    "            full_tracks_df = get_full_tracks(combined_df, min_frames=video_size)\n",
    "\n",
    "            if not full_tracks_df.empty:\n",
    "                tensor_data.append(get_tensor(full_tracks_df))\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa1d3a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tensor_data, os.path.join(output_folder, f\"tensor_data_{video}.pt\"))\n",
    "\n",
    "dataset = ClipDataset(tensor_data)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    drop_last=True,  # nur volle Batches\n",
    "    pin_memory=True  # falls auf GPU trainiert wird\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
