{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3228fb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janni\\anaconda3\\envs\\GAIL\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\janni\\anaconda3\\envs\\GAIL\\lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import ast\n",
    "import optuna\n",
    "import pickle\n",
    "import datetime\n",
    "from utils.es_utils import *\n",
    "from utils.env_utils import *\n",
    "from utils.train_utils import *\n",
    "from marl_aquarium import aquarium_v0\n",
    "from models.Buffer import Buffer, Pool\n",
    "from models.Generator import GeneratorPolicy\n",
    "from models.Discriminator import Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3aa3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "#Environment\n",
    "pred_count = 1\n",
    "prey_count = 32 \n",
    "action_count = 360\n",
    "use_walls = True\n",
    "\n",
    "# generated_trajectories\n",
    "gt_gen_episodes = 10\n",
    "gt_clip_length = 30\n",
    "\n",
    "# Buffer\n",
    "pred_buffer_size = 800\n",
    "prey_buffer_size = 24000\n",
    "\n",
    "# Training\n",
    "pred_batch_size = 128           #     32, 512\n",
    "prey_batch_size = 1024          #    256, 1024\n",
    "num_generations = 200           #     80, 200\n",
    "patience = 15                   #     20,   \n",
    "window_size = 10                #     10,\n",
    "min_slope = 0\n",
    "gen_dis_ratio = 1               #      7, 5, 1\n",
    "\n",
    "# ES-Pertrubation\n",
    "num_perturbations = 40          #     32, 40\n",
    "pert_clip_length = 15           #     10, 30, 100, 15\n",
    "sigma = 0.25                    #    0.1, 0.2, 0.25   \n",
    "gamma = 0.9997                  # 0.9997,\n",
    "lr_pred_policy = 0.03           #   0.01, 0.02, 0.03\n",
    "lr_prey_policy = 0.03           #   0.05, 0.03\n",
    "\n",
    "# RMSprop\n",
    "lr_pred_dis =  0.0005           #  0.001, 0.0005, 0.0001, 0.0005,\n",
    "lr_prey_dis = 0.0005            #  0.001, 0.0005, 0.0001, 0.0005,\n",
    "alpha=0.99                      #   0.99,\n",
    "eps_dis=1e-08                   #  1e-08,\n",
    "lambda_gp_pred = 5              #     10, 5\n",
    "lambda_gp_prey = 5              #     10, 5\n",
    "label_smoothing = True\n",
    "smooth = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef35ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Data\n",
    "video = \"video_8min\"\n",
    "num_frames=1\n",
    "total_detections=33\n",
    "\n",
    "# create training folder\n",
    "path = r\"..\\data\\training\"\n",
    "timestamp = datetime.datetime.now().strftime(\"%d.%m.%Y_%H.%M\")\n",
    "folder_name = f\"Training - {timestamp}\"\n",
    "save_dir = os.path.join(path, folder_name)\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Video folder\n",
    "raw_video_folder = rf'..\\data\\raw\\videos'\n",
    "video_path = raw_video_folder + \"\\\\\" + video + \".mp4\"\n",
    "\n",
    "# Expert Data\n",
    "data_path = rf\"..\\data\\processed\\{video}\\expert_tensors\"\n",
    "processed_video_folder = rf'..\\data\\processed\\{video}'\n",
    "ftw_path = os.path.join(processed_video_folder, \"full_track_windows\", f\"full_track_windows_{total_detections}.pkl\")\n",
    "\n",
    "with open(ftw_path, \"rb\") as f:\n",
    "    full_track_windows = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7593b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pred_policy = GeneratorPolicy().to(device)\n",
    "pred_policy.set_parameters(init=True)\n",
    "\n",
    "prey_policy = GeneratorPolicy().to(device)\n",
    "prey_policy.set_parameters(init=True)\n",
    "\n",
    "pred_discriminator = Discriminator().to(device)\n",
    "pred_discriminator.set_parameters(init=True)\n",
    "\n",
    "prey_discriminator = Discriminator().to(device)\n",
    "prey_discriminator.set_parameters(init=True)\n",
    "\n",
    "expert_buffer = Buffer(pred_max_length=pred_buffer_size, prey_max_length=prey_buffer_size, device=device)\n",
    "generative_buffer = Buffer(pred_max_length=pred_buffer_size, prey_max_length=prey_buffer_size, device=device)\n",
    "\n",
    "start_frame_pool = Pool(max_length=1000, device=device)\n",
    "start_frame_pool.generate_startframes(video_path, full_track_windows)\n",
    "\n",
    "early_stopper_pred = EarlyStoppingWindow(patience=patience, window_size=window_size, min_slope=min_slope)\n",
    "early_stopper_prey = EarlyStoppingWindow(patience=patience, window_size=window_size, min_slope=min_slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f23d55eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert Buffer is empty, load data...\n",
      "Storage of Predator Expert Buffer:  742\n",
      "Storage of Prey Expert Buffer:  23744 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Expert Data from local storage\n",
    "print(\"Expert Buffer is empty, load data...\")\n",
    "expert_buffer.add_expert(data_path, window_size=1, detections=33)\n",
    "len_exp_pred, len_exp_prey = expert_buffer.lengths()\n",
    "\n",
    "print(\"Storage of Predator Expert Buffer: \", len_exp_pred)\n",
    "print(\"Storage of Prey Expert Buffer: \", len_exp_prey, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9574015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining Policies with Behavioral Cloning on Expert Data...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pretrain Policies with Expert Data\n",
    "print(\"Pretraining Policies with Behavioral Cloning on Expert Data...\\n\")\n",
    "pred_policy = pretrain_policy(pred_policy, expert_buffer, role='predator', pred_bs=512, epochs=120, lr=1e-3, save_dir=save_dir)\n",
    "prey_policy = pretrain_policy(prey_policy, expert_buffer, role='prey', prey_bs=1024, epochs=220, lr=1e-3, save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3d702e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Generate Trajectories for Generative Buffer\\nprint(\"Generative Buffer is empty, generating data...\")\\ngenerate_trajectories(buffer=generative_buffer, start_frame_pool=start_frame_pool,\\n                        pred_count=pred_count, prey_count=prey_count, action_count=action_count, \\n                        pred_policy=pred_policy, prey_policy=prey_policy, \\n                        clip_length=gt_clip_length, num_generative_episodes=gt_gen_episodes,\\n                        use_walls=True)\\n\\nlen_gen_pred, len_gen_prey = generative_buffer.lengths()\\nprint(\"Storage of Predator Generative Buffer: \", len_gen_pred)\\nprint(\"Storage of Prey Generative Buffer: \", len_gen_prey)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Generate Trajectories for Generative Buffer\n",
    "print(\"Generative Buffer is empty, generating data...\")\n",
    "generate_trajectories(buffer=generative_buffer, start_frame_pool=start_frame_pool,\n",
    "                        pred_count=pred_count, prey_count=prey_count, action_count=action_count, \n",
    "                        pred_policy=pred_policy, prey_policy=prey_policy, \n",
    "                        clip_length=gt_clip_length, num_generative_episodes=gt_gen_episodes,\n",
    "                        use_walls=True)\n",
    "\n",
    "len_gen_pred, len_gen_prey = generative_buffer.lengths()\n",
    "print(\"Storage of Predator Generative Buffer: \", len_gen_pred)\n",
    "print(\"Storage of Prey Generative Buffer: \", len_gen_prey)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53670d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gail(pred_policy=pred_policy, prey_policy=prey_policy, \n",
    "               pred_discriminator=pred_discriminator, prey_discriminator=prey_discriminator,\n",
    "               expert_buffer=expert_buffer, generative_buffer=generative_buffer, start_frame_pool=start_frame_pool,\n",
    "               pred_count=pred_count, prey_count=prey_count, action_count=action_count, \n",
    "               use_walls=use_walls, gt_gen_episodes=gt_gen_episodes, gt_clip_length=gt_clip_length, \n",
    "               gen_dis_ratio=gen_dis_ratio, gamma=gamma, \n",
    "               alpha=alpha, eps_dis=eps_dis, \n",
    "               label_smoothing=label_smoothing, smooth=smooth,\n",
    "\n",
    "                num_generations=num_generations,\n",
    "                pred_batch_size=pred_batch_size,\n",
    "                prey_batch_size=prey_batch_size,\n",
    "                num_perturbations=num_perturbations,\n",
    "                pert_clip_length=pert_clip_length,\n",
    "                sigma=sigma,\n",
    "                lr_pred_policy=lr_pred_policy,\n",
    "                lr_prey_policy=lr_prey_policy,\n",
    "                lr_pred_dis=lr_pred_dis,\n",
    "                lr_prey_dis=lr_prey_dis,\n",
    "                lambda_gp_pred=lambda_gp_pred,\n",
    "                lambda_gp_prey=lambda_gp_prey):\n",
    "    \n",
    "    optim_dis_pred = torch.optim.RMSprop(pred_discriminator.parameters(), lr=lr_pred_dis, alpha=alpha, eps=eps_dis)\n",
    "    optim_dis_prey = torch.optim.RMSprop(prey_discriminator.parameters(), lr=lr_prey_dis, alpha=alpha, eps=eps_dis)\n",
    "\n",
    "    dis_metrics_pred = []\n",
    "    dis_metrics_prey = []\n",
    "\n",
    "    es_metrics_pred = []\n",
    "    es_metrics_prey = []\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        # Sample traj from expert and generative buffer\n",
    "        expert_pred_batch, expert_prey_batch = expert_buffer.sample(pred_batch_size, prey_batch_size)\n",
    "        policy_pred_batch, policy_prey_batch = generative_buffer.sample(pred_batch_size, prey_batch_size)\n",
    "\n",
    "        # Predator discriminator update\n",
    "        dis_metric_pred = pred_discriminator.update(expert_pred_batch, policy_pred_batch, optim_dis_pred, lambda_gp_pred, label_smoothing, smooth)\n",
    "        dis_metrics_pred.append(dis_metric_pred)\n",
    "                                        \n",
    "        # Prey discriminator update\n",
    "        dis_metric_prey = prey_discriminator.update(expert_prey_batch, policy_prey_batch, optim_dis_prey, lambda_gp_prey, label_smoothing, smooth)\n",
    "        dis_metrics_prey.append(dis_metric_prey)\n",
    "\n",
    "        for i in range(gen_dis_ratio):\n",
    "            pred_stats = pred_policy.update(\"predator\", \"pairwise\",\n",
    "                                            pred_count, prey_count, action_count,\n",
    "                                            pred_policy, prey_policy,\n",
    "                                            pred_discriminator, prey_discriminator,\n",
    "                                            num_perturbations, generation,\n",
    "                                            lr_pred_policy, lr_prey_policy,\n",
    "                                            sigma, gamma, clip_length=pert_clip_length,\n",
    "                                            use_walls=use_walls, start_frame_pool=start_frame_pool)\n",
    "            \n",
    "\n",
    "            pred_stats += pred_policy.update(\"predator\", \"attention\",\n",
    "                                            pred_count, prey_count, action_count,\n",
    "                                            pred_policy, prey_policy,\n",
    "                                            pred_discriminator, prey_discriminator,\n",
    "                                            num_perturbations, generation,\n",
    "                                            lr_pred_policy, lr_prey_policy,\n",
    "                                            sigma, gamma, clip_length=pert_clip_length,\n",
    "                                            use_walls=use_walls, start_frame_pool=start_frame_pool)\n",
    "            es_metrics_pred.append(pred_stats)\n",
    "\n",
    "\n",
    "            prey_stats = prey_policy.update(\"prey\", \"pairwise\",\n",
    "                                            pred_count, prey_count, action_count,\n",
    "                                            pred_policy, prey_policy,\n",
    "                                            pred_discriminator, prey_discriminator,\n",
    "                                            num_perturbations, generation,\n",
    "                                            lr_pred_policy, lr_prey_policy,\n",
    "                                            sigma, gamma, clip_length=pert_clip_length,\n",
    "                                            use_walls=use_walls, start_frame_pool=start_frame_pool)\n",
    "            \n",
    "            prey_stats += prey_policy.update(\"prey\", \"attention\",\n",
    "                                            pred_count, prey_count, action_count,\n",
    "                                            pred_policy, prey_policy,\n",
    "                                            pred_discriminator, prey_discriminator,\n",
    "                                            num_perturbations, generation,\n",
    "                                            lr_pred_policy, lr_prey_policy,\n",
    "                                            sigma, gamma, clip_length=pert_clip_length,\n",
    "                                            use_walls=use_walls, start_frame_pool=start_frame_pool)\n",
    "            es_metrics_prey.append(prey_stats)\n",
    "\n",
    "            # Generate new trajectories with updated policies\n",
    "            generate_trajectories(buffer=generative_buffer, start_frame_pool=start_frame_pool,\n",
    "                                    pred_count=pred_count, prey_count=prey_count, action_count=action_count, \n",
    "                                    pred_policy=pred_policy, prey_policy=prey_policy, \n",
    "                                    clip_length=gt_clip_length, num_generative_episodes=gt_gen_episodes,\n",
    "                                    use_walls=use_walls)\n",
    "\n",
    "        # also reduce globally\n",
    "        sigma *= gamma\n",
    "        lr_pred_policy *= gamma\n",
    "        lr_prey_policy *= gamma\n",
    "\n",
    "        return dis_metrics_pred, dis_metrics_prey, es_metrics_pred, es_metrics_prey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15c294f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_reward(es_metrics):\n",
    "    parsed_pd = [ast.literal_eval(d) for d in es_metrics[\"0\"]]\n",
    "    parsed_att = [ast.literal_eval(d) for d in es_metrics[\"1\"]]\n",
    "    combined = parsed_pd + parsed_att\n",
    "\n",
    "    mean_reward = sum(d['avg_reward_diff'] for d in combined) / len(combined)\n",
    "    return mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d474c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    #Environment\n",
    "    pred_count        = 1\n",
    "    prey_count        = 32 \n",
    "    action_count      = 360\n",
    "    use_walls         = True\n",
    "\n",
    "    # generated_trajectories\n",
    "    gt_gen_episodes   = 10\n",
    "    gt_clip_length    = 30\n",
    "\n",
    "    # Buffer\n",
    "    pred_buffer_size  = 800\n",
    "    prey_buffer_size  = 24000\n",
    "\n",
    "    # Training\n",
    "    num_generations   = trial.suggest_int(\"num_generations\", 50, 300)\n",
    "    pred_batch_size   = trial.suggest_categorical(\"pred_batch_size\", [64, 128, 256, 512])\n",
    "    prey_batch_size   = trial.suggest_categorical(\"prey_batch_size\", [256, 512, 1024])\n",
    "    patience          = 15\n",
    "    window_size       = 10\n",
    "    min_slope         = 0\n",
    "    gen_dis_ratio     = trial.suggest_categorical(\"gen_dis_ratio\", [1, 2, 3, 4, 5])\n",
    "\n",
    "    # ES-Pertrubation\n",
    "    num_perturbations = trial.suggest_categorical(\"num_perturbations\", [8, 16, 32, 64])\n",
    "    pert_clip_length  = trial.suggest_int(\"pert_clip_length\", 10, 30)\n",
    "    sigma             = trial.suggest_float(\"sigma\", 0.1, 0.3, log=True)\n",
    "    lr_pred_policy    = trial.suggest_float(\"lr_pred_policy\", 0.0001, 0.01, log=True)\n",
    "    lr_prey_policy    = trial.suggest_float(\"lr_prey_policy\", 0.0001, 0.01, log=True)\n",
    "    gamma             = 0.9997\n",
    "\n",
    "    # RMSprop\n",
    "    lr_pred_dis       = trial.suggest_float(\"lr_pred_dis\", 0.0001, 0.01, log=True)\n",
    "    lr_prey_dis       = trial.suggest_float(\"lr_prey_dis\", 0.0001, 0.01, log=True)\n",
    "    lambda_gp_pred    = trial.suggest_int(\"lambda_gp_pred\", 1, 10)\n",
    "    lambda_gp_prey    = trial.suggest_int(\"lambda_gp_prey\", 1, 10)\n",
    "    alpha             = 0.99\n",
    "    eps_dis           = 1e-08\n",
    "    label_smoothing   = trial.suggest_categorical(\"label_smoothing\", [True, False])\n",
    "    smooth            = 0.1\n",
    "\n",
    "\n",
    "    dis_metrics_pred, dis_metrics_prey, es_metrics_pred, es_metrics_prey = train_gail(num_generations=num_generations,\n",
    "                                                                                      pred_batch_size=pred_batch_size,\n",
    "                                                                                      prey_batch_size=prey_batch_size,\n",
    "                                                                                      gen_dis_ratio=gen_dis_ratio,\n",
    "                                                                                      num_perturbations=num_perturbations,\n",
    "                                                                                      pert_clip_length=pert_clip_length,\n",
    "                                                                                      sigma=sigma,\n",
    "                                                                                      lr_pred_policy=lr_pred_policy,\n",
    "                                                                                      lr_prey_policy=lr_prey_policy,\n",
    "                                                                                      lr_pred_dis=lr_pred_dis,\n",
    "                                                                                      lr_prey_dis=lr_prey_dis,\n",
    "                                                                                      lambda_gp_pred=lambda_gp_pred,\n",
    "                                                                                      lambda_gp_prey=lambda_gp_prey,\n",
    "                                                                                      label_smoothing=label_smoothing)\n",
    "\n",
    "    pred_reward = get_mean_reward(es_metrics_pred)\n",
    "    prey_reward = get_mean_reward(es_metrics_prey)\n",
    "\n",
    "    return pred_reward, prey_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66c41a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-25 15:15:55,491] A new study created in memory with name: no-name-669d91d9-41b1-4328-9201-81b1aa323317\n",
      "[W 2025-07-25 15:15:55,498] Trial 0 failed with parameters: {'num_generations': 124, 'pred_batch_size': 128, 'prey_batch_size': 1024, 'gen_dis_ratio': 1, 'num_perturbations': 16, 'pert_clip_length': 18, 'sigma': 0.15655650375074728, 'lr_pred_policy': 0.0046737343217495755, 'lr_prey_policy': 0.004885381816388644, 'lr_pred_dis': 0.00014614450233452555, 'lr_prey_dis': 0.0010200740379280805, 'lambda_gp_pred': 8, 'lambda_gp_prey': 3, 'label_smoothing': True} because of the following error: ValueError('Sample larger than population or is negative').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\GAIL\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\janni\\AppData\\Local\\Temp\\ipykernel_8104\\3600978565.py\", line 44, in objective\n",
      "    dis_metrics_pred, dis_metrics_prey, es_metrics_pred, es_metrics_prey = train_gail(num_generations=num_generations,\n",
      "  File \"C:\\Users\\janni\\AppData\\Local\\Temp\\ipykernel_8104\\4175451834.py\", line 35, in train_gail\n",
      "    policy_pred_batch, policy_prey_batch = generative_buffer.sample(pred_batch_size, prey_batch_size)\n",
      "  File \"c:\\Users\\janni\\OneDrive\\Dokumente\\Privat\\Bildung\\M. Sc. Social and Economic Data Science\\4. Semester\\Master Thesis\\Code\\notebooks\\models\\Buffer.py\", line 63, in sample\n",
      "    pred_idx = random.sample(range(len_pred), pred_batch_size)\n",
      "  File \"c:\\Users\\janni\\anaconda3\\envs\\GAIL\\lib\\random.py\", line 482, in sample\n",
      "    raise ValueError(\"Sample larger than population or is negative\")\n",
      "ValueError: Sample larger than population or is negative\n",
      "[W 2025-07-25 15:15:55,511] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(directions\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[0;32m      2\u001b[0m                             sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(), \u001b[38;5;66;03m# Bayesian Optimization\u001b[39;00m\n\u001b[0;32m      3\u001b[0m                             pruner\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mMedianPruner()) \u001b[38;5;66;03m# Stopping trials that are not promising\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\GAIL\\lib\\site-packages\\optuna\\study\\study.py:489\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    389\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    397\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    398\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\GAIL\\lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 64\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\GAIL\\lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\GAIL\\lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    249\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    252\u001b[0m ):\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\GAIL\\lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[13], line 44\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     40\u001b[0m label_smoothing   \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_smoothing\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m])\n\u001b[0;32m     41\u001b[0m smooth            \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m---> 44\u001b[0m dis_metrics_pred, dis_metrics_prey, es_metrics_pred, es_metrics_prey \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_gail\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_generations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_generations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mpred_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mprey_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprey_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mgen_dis_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_dis_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mnum_perturbations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_perturbations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mpert_clip_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpert_clip_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mlr_pred_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_pred_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mlr_prey_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_prey_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mlr_pred_dis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_pred_dis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mlr_prey_dis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_prey_dis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mlambda_gp_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_gp_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mlambda_gp_prey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_gp_prey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m pred_reward \u001b[38;5;241m=\u001b[39m get_mean_reward(es_metrics_pred)\n\u001b[0;32m     60\u001b[0m prey_reward \u001b[38;5;241m=\u001b[39m get_mean_reward(es_metrics_prey)\n",
      "Cell \u001b[1;32mIn[8], line 35\u001b[0m, in \u001b[0;36mtrain_gail\u001b[1;34m(pred_policy, prey_policy, pred_discriminator, prey_discriminator, expert_buffer, generative_buffer, start_frame_pool, pred_count, prey_count, action_count, use_walls, gt_gen_episodes, gt_clip_length, gen_dis_ratio, gamma, alpha, eps_dis, label_smoothing, smooth, num_generations, pred_batch_size, prey_batch_size, num_perturbations, pert_clip_length, sigma, lr_pred_policy, lr_prey_policy, lr_pred_dis, lr_prey_dis, lambda_gp_pred, lambda_gp_prey)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m generation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_generations):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Sample traj from expert and generative buffer\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     expert_pred_batch, expert_prey_batch \u001b[38;5;241m=\u001b[39m expert_buffer\u001b[38;5;241m.\u001b[39msample(pred_batch_size, prey_batch_size)\n\u001b[1;32m---> 35\u001b[0m     policy_pred_batch, policy_prey_batch \u001b[38;5;241m=\u001b[39m \u001b[43mgenerative_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprey_batch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# Predator discriminator update\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     dis_metric_pred \u001b[38;5;241m=\u001b[39m pred_discriminator\u001b[38;5;241m.\u001b[39mupdate(expert_pred_batch, policy_pred_batch, optim_dis_pred, lambda_gp_pred, label_smoothing, smooth)\n",
      "File \u001b[1;32mc:\\Users\\janni\\OneDrive\\Dokumente\\Privat\\Bildung\\M. Sc. Social and Economic Data Science\\4. Semester\\Master Thesis\\Code\\notebooks\\models\\Buffer.py:63\u001b[0m, in \u001b[0;36mBuffer.sample\u001b[1;34m(self, pred_batch_size, prey_batch_size)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, pred_batch_size, prey_batch_size):\n\u001b[0;32m     61\u001b[0m     len_pred, len_prey \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlengths()\n\u001b[1;32m---> 63\u001b[0m     pred_idx \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlen_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_batch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     prey_idx \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(len_prey), prey_batch_size)\n\u001b[0;32m     66\u001b[0m     pred_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_buffer[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m pred_idx], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[1;32mc:\\Users\\janni\\anaconda3\\envs\\GAIL\\lib\\random.py:482\u001b[0m, in \u001b[0;36mRandom.sample\u001b[1;34m(self, population, k, counts)\u001b[0m\n\u001b[0;32m    480\u001b[0m randbelow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n\u001b[1;32m--> 482\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample larger than population or is negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    483\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m k\n\u001b[0;32m    484\u001b[0m setsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m21\u001b[39m        \u001b[38;5;66;03m# size of a small set minus size of an empty list\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(directions=[\"maximize\", \"maximize\"], \n",
    "                            sampler=optuna.samplers.TPESampler(), # Bayesian Optimization\n",
    "                            pruner=optuna.pruners.MedianPruner()) # Stopping trials that are not promising\n",
    "\n",
    "study.optimize(objective, n_trials=100, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4fdc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best value:\", study.best_value)\n",
    "\n",
    "optuna.visualization.plot_optimization_history(study).show()\n",
    "optuna.visualization.plot_param_importances(study).show()\n",
    "optuna.visualization.plot_slice(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAIL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
